{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0V3VhZx93jkA"
   },
   "source": [
    "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
    "<div class=\"align-center\">\n",
    "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
    "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
    "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐\n",
    "</div>\n",
    "\n",
    "To install Unsloth your local device, follow [our guide](https://docs.unsloth.ai/get-started/install-and-update). This notebook is licensed [LGPL-3.0](https://github.com/unslothai/notebooks?tab=LGPL-3.0-1-ov-file#readme).\n",
    "\n",
    "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xVOFmbn3jkC"
   },
   "source": [
    "### News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaczNEK93jkC"
   },
   "source": [
    "\n",
    "Unsloth's [Docker image](https://hub.docker.com/r/unsloth/unsloth) is here! Start training with no setup & environment issues. [Read our Guide](https://docs.unsloth.ai/new/how-to-train-llms-with-unsloth-and-docker).\n",
    "\n",
    "[gpt-oss RL](https://docs.unsloth.ai/new/gpt-oss-reinforcement-learning) is now supported with the fastest inference & lowest VRAM. Try our [new notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-GRPO.ipynb) which creates kernels!\n",
    "\n",
    "Introducing [Vision](https://docs.unsloth.ai/new/vision-reinforcement-learning-vlm-rl) and [Standby](https://docs.unsloth.ai/basics/memory-efficient-rl) for RL! Train Qwen, Gemma etc. VLMs with GSPO - even faster with less VRAM.\n",
    "\n",
    "Unsloth now supports Text-to-Speech (TTS) models. Read our [guide here](https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning).\n",
    "\n",
    "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4xFjFzH3jkD"
   },
   "source": [
    "### Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300,
     "referenced_widgets": [
      "b03af9d3d3074c9fb43cc45d456b8e30",
      "4aab9fa7e38a49e59f87515e7bf415ee",
      "cba1bb5319c04c4c8adbc2304af6dde7",
      "af205ba151054c5fa8a5761b24dc8445",
      "45d8edc7203e4d2081170777d5eda422",
      "86f7a51468b248c8bb32c184f7cc4a69",
      "43efda3bc6a5496aab27c30c99577825",
      "0d2d931811914399b33af27d741cdbd2",
      "7190e73a16b34eaabf2e3fc00f17246e",
      "f9031d9400464ce4a500bd5b0b1b1fc7",
      "33f7cdb4b1484ff08d5882e38ed4ff33",
      "6f6d146e3dc1428682d6f9c193f8bf19",
      "6919b1082780411aa9310ceb152ea6e0",
      "8f9e359dcc0d4e4495eaa1f3920e803b",
      "8a41d23dbbdb44f4aab5f453c4be58a4",
      "f06db96ad2414b679cc0b55f25ff16db",
      "99e3b13809ca4873a44189f298084c59",
      "701f88ce88074492a3a8b3470e8b22e7",
      "b91f7a6e50b5463bb560e45a71ee1998",
      "f7ef65c1668c498bb72ba3411301e116",
      "3d8e6f188bf44dba981e445d8bea3402",
      "a615710d2f72406f94586cf44320d1d8",
      "5064b0b9c6d7462190bcd6059a6475f4",
      "19474c3fd67d4a0a9071442553eea424",
      "cdc0128cc0ea40bc949df6412d179b78",
      "b28fd98a29b04febac41b3f0169c72a1",
      "e0d4b6fedf2245e1b926c36bc7d792e6",
      "a51f8804e64e41f4b5f403bb48f97739",
      "7d182abc791a4529a1d022c73f147743",
      "b13a48803a164e7caecfb06e2bde1556",
      "9bc07321be954d109b8f27d4b8f181dd",
      "6c96874fffb648708eba436836dec3c7",
      "8c321f9d450c45259553f244cea495ce",
      "665de9c511234f50b95f019e30553647",
      "7833e5ff39994bd8af56ab74ca5a6282",
      "05e9011d5fd44a219ef86ce93b400cdb",
      "9009e3ae003b4189bbfc8f6d20e425db",
      "feddd2b94ff640019168f085886042ca",
      "66d602f02ee94a9fb9bb3ef6ebb157a2",
      "bad159b09d454000bba39dba607b8e60",
      "e16a04efe0564f13bda5d36487b79053",
      "9b918d8d5f674be88e05c0f3fc365b77",
      "1c514cd5db254fd887496cfcea29b203",
      "4f78fb604b944c8da3f8f94a84779533",
      "571fbb27971e4af0b958591a502e1249",
      "d792fa2e810a4aec841b96aed03f22e5",
      "5a927d80c3d841768f8a32abc2b3da4e",
      "60a2e5edb2424b91b551abaf8607d225",
      "aa461878d707464ea5728e857199fc1b",
      "c2ec9b62f02b4813ab4d7a7c4609ec57",
      "7949c2ae13f44c609de332549305efd4",
      "3f30c80db3c54588b79e9352f57e783d",
      "6e059c44581046c6b7ac232fac94c6a4",
      "6b2f0019c68b4ca385fc9e9641e98006",
      "3bfbb892f9fe4c7baec8518c5fc27fd3"
     ]
    },
    "id": "QmUBVEnvCDJv",
    "outputId": "c36582a5-ee6c-483c-8a5b-9ec43430d2af",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unsloth_zoo.log: Unsloth: Patching vLLM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-03 09:52:11 [vllm_utils.py:689] Unsloth: Patching vLLM v1 graph capture\n",
      "INFO 12-03 09:52:11 [vllm_utils.py:717] Unsloth: Patching vLLM v0 graph capture\n",
      "==((====))==  Unsloth 2025.10.3: Fast Llama patching. Transformers: 4.56.2. vLLM: 0.10.2.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 1. Max memory: 23.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33+f204359.d20251014. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: vLLM loading unsloth/Llama-3.2-3B-Instruct with actual GPU utilization = 39.93%\n",
      "Unsloth: Your GPU has CUDA compute capability 8.9 with VRAM = 23.99 GB.\n",
      "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 2048. Num Sequences = 160.\n",
      "Unsloth: vLLM's KV Cache can use up to 3.41 GB. Also swap space = 2 GB.\n",
      "WARNING 12-03 09:52:13 [compilation.py:456] full_cuda_graph is deprecated, use cudagraph_mode=FULL instead.\n",
      "Unsloth: Not an error, but `device` is not supported in vLLM. Skipping.\n",
      "INFO 12-03 09:52:13 [utils.py:328] non-default args: {'dtype': torch.bfloat16, 'seed': 0, 'max_model_len': 2048, 'enable_prefix_caching': True, 'swap_space': 2, 'gpu_memory_utilization': 0.399308003681784, 'max_num_batched_tokens': 2048, 'max_num_seqs': 160, 'max_logprobs': 0, 'disable_log_stats': True, 'enable_lora': True, 'max_lora_rank': 64, 'enable_chunked_prefill': True, 'compilation_config': {\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":null,\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":32,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":2,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":null,\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"pass_config\":{},\"max_capture_size\":null,\"local_cache_dir\":null}, 'model': 'unsloth/Llama-3.2-3B-Instruct'}\n",
      "INFO 12-03 09:52:19 [__init__.py:742] Resolved architecture: LlamaForCausalLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-03 09:52:19 [__init__.py:1815] Using max model len 2048\n",
      "INFO 12-03 09:52:21 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
      "WARNING 12-03 09:52:21 [lora.py:92] `lora_extra_vocab_size` is deprecated and will be removed in v0.12.0. Additional vocabulary support for LoRA adapters is being phased out.\n",
      "INFO 12-03 09:52:21 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='unsloth/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='unsloth/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/Llama-3.2-3B-Instruct, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":32,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":2,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"pass_config\":{},\"max_capture_size\":320,\"local_cache_dir\":null}\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "INFO 12-03 09:52:21 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "WARNING 12-03 09:52:21 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 12-03 09:52:21 [gpu_model_runner.py:2338] Starting to load model unsloth/Llama-3.2-3B-Instruct...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W1203 09:52:21.995478712 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-03 09:52:22 [gpu_model_runner.py:2370] Loading model from scratch...\n",
      "INFO 12-03 09:52:22 [cuda.py:362] Using Flash Attention backend on V1 engine.\n",
      "INFO 12-03 09:52:26 [weight_utils.py:348] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7bc0bcbfbe4f159ba0c32c24d7ed02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-03 09:52:33 [default_loader.py:268] Loading weights took 6.64 seconds\n",
      "INFO 12-03 09:52:33 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "INFO 12-03 09:52:33 [gpu_model_runner.py:2392] Model loading took 6.2472 GiB and 11.046489 seconds\n",
      "INFO 12-03 09:52:38 [backends.py:539] Using cache directory: /home/unsloth/.cache/vllm/torch_compile_cache/4098b52d57/rank_0_0/backbone for vLLM's torch.compile\n",
      "INFO 12-03 09:52:38 [backends.py:550] Dynamo bytecode transform time: 4.40 s\n",
      "INFO 12-03 09:52:40 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 1.600 s\n",
      "INFO 12-03 09:52:42 [monitor.py:34] torch.compile takes 4.40 s in total\n",
      "Unsloth: Retrying vLLM to process 120 sequences and 2048 tokens in tandem.\n",
      "Error:\n",
      "Error in memory profiling. Initial free memory 10.563451766967773 GiB, current free memory 16.048828125 GiB. This happens when other processes sharing the same container release GPU memory while vLLM is profiling during initialization. To fix this, ensure consistent GPU memory allocation or isolate vLLM in its own container.\n",
      "INFO 12-03 09:52:43 [utils.py:328] non-default args: {'dtype': torch.bfloat16, 'seed': 0, 'max_model_len': 2048, 'enable_prefix_caching': True, 'swap_space': 2, 'gpu_memory_utilization': 0.33941180312951635, 'max_num_batched_tokens': 2048, 'max_num_seqs': 120, 'max_logprobs': 0, 'disable_log_stats': True, 'enable_lora': True, 'max_lora_rank': 64, 'enable_chunked_prefill': True, 'compilation_config': {\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"/home/unsloth/.cache/vllm/torch_compile_cache/4098b52d57\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":32,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":2,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"pass_config\":{},\"max_capture_size\":320,\"local_cache_dir\":\"/home/unsloth/.cache/vllm/torch_compile_cache/4098b52d57/rank_0_0/backbone\"}, 'model': 'unsloth/Llama-3.2-3B-Instruct'}\n",
      "INFO 12-03 09:52:43 [__init__.py:742] Resolved architecture: LlamaForCausalLM\n",
      "INFO 12-03 09:52:43 [__init__.py:1815] Using max model len 2048\n",
      "INFO 12-03 09:52:44 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
      "WARNING 12-03 09:52:44 [lora.py:92] `lora_extra_vocab_size` is deprecated and will be removed in v0.12.0. Additional vocabulary support for LoRA adapters is being phased out.\n",
      "INFO 12-03 09:52:44 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='unsloth/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='unsloth/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/Llama-3.2-3B-Instruct, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"/home/unsloth/.cache/vllm/torch_compile_cache/4098b52d57\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":32,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":2,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"pass_config\":{},\"max_capture_size\":320,\"local_cache_dir\":\"/home/unsloth/.cache/vllm/torch_compile_cache/4098b52d57/rank_0_0/backbone\"}\n",
      "INFO 12-03 09:52:45 [gpu_model_runner.py:2338] Starting to load model unsloth/Llama-3.2-3B-Instruct...\n",
      "INFO 12-03 09:52:45 [gpu_model_runner.py:2370] Loading model from scratch...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Duplicate layer name: model.layers.0.self_attn.attn",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/unsloth_zoo/vllm_utils.py:1669\u001b[39m, in \u001b[36mload_vllm\u001b[39m\u001b[34m(model_name, config, gpu_memory_utilization, max_seq_length, dtype, training, float8_kv_cache, random_state, enable_lora, max_lora_rank, max_loras, use_async, use_engine, disable_log_stats, enforce_eager, enable_prefix_caching, compilation_config, conservativeness, max_logprobs, use_bitsandbytes, unsloth_vllm_standby, is_vision_model, return_args)\u001b[39m\n\u001b[32m   1668\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1669\u001b[39m     llm = \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1670\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/entrypoints/llm.py:282\u001b[39m, in \u001b[36mLLM.__init__\u001b[39m\u001b[34m(self, model, runner, convert, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, hf_token, hf_overrides, mm_processor_kwargs, override_pooler_config, kv_cache_memory_bytes, compilation_config, logits_processors, **kwargs)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;66;03m# Create the Engine (autoselects V0 vs V1)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m \u001b[38;5;28mself\u001b[39m.llm_engine = \u001b[43mLLMEngine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUsageContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[38;5;28mself\u001b[39m.engine_class = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm_engine)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/engine/llm_engine.py:493\u001b[39m, in \u001b[36mLLMEngine.from_engine_args\u001b[39m\u001b[34m(cls, engine_args, usage_context, stat_loggers)\u001b[39m\n\u001b[32m    491\u001b[39m     engine_cls = V1LLMEngine\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mengine_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_vllm_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m    \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/v1/engine/llm_engine.py:134\u001b[39m, in \u001b[36mLLMEngine.from_vllm_config\u001b[39m\u001b[34m(cls, vllm_config, usage_context, stat_loggers, disable_log_stats)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_vllm_config\u001b[39m(\n\u001b[32m    128\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    132\u001b[39m     disable_log_stats: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    133\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mLLMEngine\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m               \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mExecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m               \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m               \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m               \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m               \u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43menvs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVLLM_ENABLE_V1_MULTIPROCESSING\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/v1/engine/llm_engine.py:111\u001b[39m, in \u001b[36mLLMEngine.__init__\u001b[39m\u001b[34m(self, vllm_config, executor_class, log_stats, usage_context, stat_loggers, mm_registry, use_cached_outputs, multiprocess_mode)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# EngineCore (gets EngineCoreRequests and gives EngineCoreOutputs)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m \u001b[38;5;28mself\u001b[39m.engine_core = \u001b[43mEngineCoreClient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43masyncio_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m multiprocess_mode:\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# for v0 compatibility\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/v1/engine/core_client.py:82\u001b[39m, in \u001b[36mEngineCoreClient.make_client\u001b[39m\u001b[34m(multiprocess_mode, asyncio_mode, vllm_config, executor_class, log_stats)\u001b[39m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SyncMPClient(vllm_config, executor_class, log_stats)\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mInprocClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/v1/engine/core_client.py:245\u001b[39m, in \u001b[36mInprocClient.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m     \u001b[38;5;28mself\u001b[39m.engine_core = \u001b[43mEngineCore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/v1/engine/core.py:82\u001b[39m, in \u001b[36mEngineCore.__init__\u001b[39m\u001b[34m(self, vllm_config, executor_class, log_stats, executor_fail_callback)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# Setup Model.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28mself\u001b[39m.model_executor = \u001b[43mexecutor_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m executor_fail_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/executor/executor_base.py:54\u001b[39m, in \u001b[36mExecutorBase.__init__\u001b[39m\u001b[34m(self, vllm_config)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mself\u001b[39m.observability_config = vllm_config.observability_config\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28mself\u001b[39m.is_sleeping = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/executor/uniproc_executor.py:49\u001b[39m, in \u001b[36mUniProcExecutor._init_executor\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mself\u001b[39m.collective_rpc(\u001b[33m\"\u001b[39m\u001b[33minit_device\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollective_rpc\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mload_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/executor/uniproc_executor.py:58\u001b[39m, in \u001b[36mUniProcExecutor.collective_rpc\u001b[39m\u001b[34m(self, method, timeout, args, kwargs)\u001b[39m\n\u001b[32m     57\u001b[39m     kwargs = {}\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m answer = \u001b[43mrun_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdriver_worker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [answer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/utils/__init__.py:3060\u001b[39m, in \u001b[36mrun_method\u001b[39m\u001b[34m(obj, method, args, kwargs)\u001b[39m\n\u001b[32m   3059\u001b[39m     func = partial(method, obj)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3060\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/v1/worker/gpu_worker.py:213\u001b[39m, in \u001b[36mWorker.load_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._maybe_get_memory_pool_context(tag=\u001b[33m\"\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_runner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43meep_scale_up\u001b[49m\u001b[43m=\u001b[49m\u001b[43meep_scale_up\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/v1/worker/gpu_model_runner.py:2371\u001b[39m, in \u001b[36mGPUModelRunner.load_model\u001b[39m\u001b[34m(self, eep_scale_up)\u001b[39m\n\u001b[32m   2370\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mLoading model from scratch...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2371\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[43mmodel_loader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2373\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lora_config:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/model_executor/model_loader/base_loader.py:45\u001b[39m, in \u001b[36mBaseModelLoader.load_model\u001b[39m\u001b[34m(self, vllm_config, model_config)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m target_device:\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     model = \u001b[43minitialize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m logger.debug(\u001b[33m\"\u001b[39m\u001b[33mLoading weights on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m ...\u001b[39m\u001b[33m\"\u001b[39m, load_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/model_executor/model_loader/utils.py:64\u001b[39m, in \u001b[36minitialize_model\u001b[39m\u001b[34m(vllm_config, prefix, model_class, model_config)\u001b[39m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_current_vllm_config(vllm_config,\n\u001b[32m     62\u001b[39m                                  check_compile=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     63\u001b[39m                                  prefix=prefix):\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m msg = (\u001b[33m\"\u001b[39m\u001b[33mvLLM model class should accept `vllm_config` and `prefix` as \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     67\u001b[39m        \u001b[33m\"\u001b[39m\u001b[33minput arguments. Possibly you have an old-style model class\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     68\u001b[39m        \u001b[33m\"\u001b[39m\u001b[33m registered from out of tree and it is used for new vLLM version. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     69\u001b[39m        \u001b[33m\"\u001b[39m\u001b[33mCheck https://docs.vllm.ai/en/latest/design/arch_overview.html \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m        \u001b[33m\"\u001b[39m\u001b[33mfor the design and update the model class accordingly.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/model_executor/models/llama.py:537\u001b[39m, in \u001b[36mLlamaForCausalLM.__init__\u001b[39m\u001b[34m(self, vllm_config, prefix, layer_type)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28mself\u001b[39m.lora_config = lora_config\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_prefix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mlayer_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m get_pp_group().is_last_rank:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/model_executor/models/llama.py:583\u001b[39m, in \u001b[36mLlamaForCausalLM._init_model\u001b[39m\u001b[34m(self, vllm_config, prefix, layer_type)\u001b[39m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_init_model\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    580\u001b[39m                 vllm_config: VllmConfig,\n\u001b[32m    581\u001b[39m                 prefix: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    582\u001b[39m                 layer_type: \u001b[38;5;28mtype\u001b[39m[nn.Module] = LlamaDecoderLayer):\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLlamaModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mlayer_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/compilation/decorators.py:199\u001b[39m, in \u001b[36m_support_torch_compile.<locals>.__init__\u001b[39m\u001b[34m(self, vllm_config, prefix, **kwargs)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *, vllm_config: VllmConfig, prefix: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[43mold_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m     \u001b[38;5;28mself\u001b[39m.vllm_config = vllm_config\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/model_executor/models/llama.py:359\u001b[39m, in \u001b[36mLlamaModel.__init__\u001b[39m\u001b[34m(self, vllm_config, prefix, layer_type)\u001b[39m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28mself\u001b[39m.embed_tokens = PPMissingLayer()\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m \u001b[38;5;28mself\u001b[39m.start_layer, \u001b[38;5;28mself\u001b[39m.end_layer, \u001b[38;5;28mself\u001b[39m.layers = \u001b[43mmake_layers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_hidden_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.layers\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m get_pp_group().is_last_rank:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/model_executor/models/utils.py:642\u001b[39m, in \u001b[36mmake_layers\u001b[39m\u001b[34m(num_hidden_layers, layer_fn, prefix)\u001b[39m\n\u001b[32m    638\u001b[39m start_layer, end_layer = get_pp_indices(num_hidden_layers,\n\u001b[32m    639\u001b[39m                                         get_pp_group().rank_in_group,\n\u001b[32m    640\u001b[39m                                         get_pp_group().world_size)\n\u001b[32m    641\u001b[39m modules = torch.nn.ModuleList(\n\u001b[32m--> \u001b[39m\u001b[32m642\u001b[39m     [PPMissingLayer() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_layer)] + \u001b[43m[\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaybe_offload_to_cpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43midx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m + [PPMissingLayer() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(end_layer, num_hidden_layers)])\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m start_layer, end_layer, modules\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/model_executor/models/utils.py:643\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    638\u001b[39m start_layer, end_layer = get_pp_indices(num_hidden_layers,\n\u001b[32m    639\u001b[39m                                         get_pp_group().rank_in_group,\n\u001b[32m    640\u001b[39m                                         get_pp_group().world_size)\n\u001b[32m    641\u001b[39m modules = torch.nn.ModuleList(\n\u001b[32m    642\u001b[39m     [PPMissingLayer() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_layer)] + [\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m         maybe_offload_to_cpu(\u001b[43mlayer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43midx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    644\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_layer, end_layer)\n\u001b[32m    645\u001b[39m     ] + [PPMissingLayer() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(end_layer, num_hidden_layers)])\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m start_layer, end_layer, modules\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/model_executor/models/llama.py:361\u001b[39m, in \u001b[36mLlamaModel.__init__.<locals>.<lambda>\u001b[39m\u001b[34m(prefix)\u001b[39m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28mself\u001b[39m.embed_tokens = PPMissingLayer()\n\u001b[32m    359\u001b[39m \u001b[38;5;28mself\u001b[39m.start_layer, \u001b[38;5;28mself\u001b[39m.end_layer, \u001b[38;5;28mself\u001b[39m.layers = make_layers(\n\u001b[32m    360\u001b[39m     config.num_hidden_layers,\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m prefix: \u001b[43mlayer_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    365\u001b[39m     prefix=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.layers\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    366\u001b[39m )\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m get_pp_group().is_last_rank:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/model_executor/models/llama.py:276\u001b[39m, in \u001b[36mLlamaDecoderLayer.__init__\u001b[39m\u001b[34m(self, config, cache_config, quant_config, prefix)\u001b[39m\n\u001b[32m    274\u001b[39m     attn_type = AttentionType.ENCODER_ONLY\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m \u001b[38;5;28mself\u001b[39m.self_attn = \u001b[43mLlamaAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_attention_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_kv_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnum_key_value_heads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_attention_heads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrope_theta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrope_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbias_o_proj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbias_o_proj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.self_attn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[38;5;28mself\u001b[39m.mlp = LlamaMLP(\n\u001b[32m    293\u001b[39m     hidden_size=\u001b[38;5;28mself\u001b[39m.hidden_size,\n\u001b[32m    294\u001b[39m     intermediate_size=config.intermediate_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m    298\u001b[39m     prefix=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.mlp\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    299\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/model_executor/models/llama.py:196\u001b[39m, in \u001b[36mLlamaAttention.__init__\u001b[39m\u001b[34m(self, config, hidden_size, num_heads, num_kv_heads, rope_theta, rope_scaling, max_position_embeddings, quant_config, bias, bias_o_proj, cache_config, prefix, attn_type)\u001b[39m\n\u001b[32m    193\u001b[39m attn_cls = (EncoderOnlyAttention\n\u001b[32m    194\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m attn_type == AttentionType.ENCODER_ONLY \u001b[38;5;28;01melse\u001b[39;00m Attention)\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28mself\u001b[39m.attn = \u001b[43mattn_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhead_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_kv_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_kv_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_layer_sliding_window\u001b[49m\u001b[43m=\u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.attn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/vllm/attention/layer.py:198\u001b[39m, in \u001b[36mAttention.__init__\u001b[39m\u001b[34m(self, num_heads, head_size, scale, num_kv_heads, alibi_slopes, cache_config, quant_config, logits_soft_cap, per_layer_sliding_window, use_mla, prefix, attn_type, kv_sharing_target_layer_name, attn_backend, **extra_impl_args)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01min\u001b[39;00m compilation_config.static_forward_context:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDuplicate layer name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    199\u001b[39m compilation_config.static_forward_context[prefix] = \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Duplicate layer name: model.layers.0.self_attn.attn",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\u001b[39;00m\n\u001b[32m      8\u001b[39m fourbit_models = [\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33munsloth/mistral-7b-v0.3-bnb-4bit\u001b[39m\u001b[33m\"\u001b[39m,      \u001b[38;5;66;03m# New Mistral v3 2x faster!\u001b[39;00m\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33munsloth/mistral-7b-instruct-v0.3-bnb-4bit\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33munsloth/gemma-7b-bnb-4bit\u001b[39m\u001b[33m\"\u001b[39m,             \u001b[38;5;66;03m# Gemma 2.2x faster!\u001b[39;00m\n\u001b[32m     18\u001b[39m ] \u001b[38;5;66;03m# More models at https://huggingface.co/unsloth\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m model, tokenizer = \u001b[43mFastLanguageModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmeta-llama/Llama-3.2-3B-Instruct\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# False for LoRA 16bit\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfast_inference\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Enable vLLM fast inference\u001b[39;49;00m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Reduce if out of memory\u001b[39;49;00m\n\u001b[32m     26\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/unsloth/models/loader.py:446\u001b[39m, in \u001b[36mFastLanguageModel.from_pretrained\u001b[39m\u001b[34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, load_in_16bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, offload_embedding, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, qat_scheme, *args, **kwargs)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fast_inference:\n\u001b[32m    444\u001b[39m     fast_inference, model_name = fast_inference_setup(model_name, model_config)\n\u001b[32m--> \u001b[39m\u001b[32m446\u001b[39m model, tokenizer = \u001b[43mdispatch_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_get_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_patcher\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdispatch_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m          \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_peft\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfast_inference\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfast_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfloat8_kv_cache\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloat8_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_lora_rank\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lora_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resize_model_vocab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    470\u001b[39m     model.resize_token_embeddings(resize_model_vocab)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/unsloth/models/llama.py:2059\u001b[39m, in \u001b[36mFastLlamaModel.from_pretrained\u001b[39m\u001b[34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, revision, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, unsloth_vllm_standby, num_labels, qat_scheme, **kwargs)\u001b[39m\n\u001b[32m   2056\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   2058\u001b[39m \u001b[38;5;66;03m# Load vLLM first\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2059\u001b[39m llm = \u001b[43mload_vllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mload_vllm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2061\u001b[39m \u001b[38;5;66;03m# Convert to HF format\u001b[39;00m\n\u001b[32m   2062\u001b[39m _, quant_state_dict = get_vllm_state_dict(llm, config = model_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/unsloth_zoo/vllm_utils.py:1683\u001b[39m, in \u001b[36mload_vllm\u001b[39m\u001b[34m(model_name, config, gpu_memory_utilization, max_seq_length, dtype, training, float8_kv_cache, random_state, enable_lora, max_lora_rank, max_loras, use_async, use_engine, disable_log_stats, enforce_eager, enable_prefix_caching, compilation_config, conservativeness, max_logprobs, use_bitsandbytes, unsloth_vllm_standby, is_vision_model, return_args)\u001b[39m\n\u001b[32m   1679\u001b[39m error = \u001b[38;5;28mstr\u001b[39m(error)\n\u001b[32m   1680\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trials >= \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m unsloth_vllm_standby:\n\u001b[32m   1681\u001b[39m     \u001b[38;5;66;03m# Sleep mode uses CuMemAllocator which can't run multiple instances in single process.\u001b[39;00m\n\u001b[32m   1682\u001b[39m     \u001b[38;5;66;03m# We can't do retry because vLLM will fail to load with said error.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1683\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(error)\n\u001b[32m   1685\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgpu_memory_utilization\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmemory\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error:\n\u001b[32m   1686\u001b[39m     approx_max_num_seqs = \u001b[38;5;28mint\u001b[39m(approx_max_num_seqs * \u001b[32m0.75\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Duplicate layer name: model.layers.0.self_attn.attn"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",      # New Mistral v3 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/llama-3-8b-bnb-4bit\",           # Llama-3 15 trillion tokens model 2x faster!\n",
    "    \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
    "    \"unsloth/llama-3-70b-bnb-4bit\",\n",
    "    \"unsloth/Phi-3-mini-4k-instruct\",        # Phi-3 2x faster!\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/mistral-7b-bnb-4bit\",\n",
    "    \"unsloth/gemma-7b-bnb-4bit\",             # Gemma 2.2x faster!\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = False, # False for LoRA 16bit\n",
    "    fast_inference = True, # Enable vLLM fast inference\n",
    "    gpu_memory_utilization = 0.9, # Reduce if out of memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXd9bTZd1aaL"
   },
   "source": [
    "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bZsfBuZDeCL",
    "outputId": "b2a0373b-a721-4170-d7d3-8e6f6a33b0d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Not an error, but Unsloth cannot patch MLP layers with our manual autograd engine since either LoRA adapters\n",
      "are not enabled or a bias term (like in Qwen) is used.\n",
      "Not an error, but Unsloth cannot patch Attention layers with our manual autograd engine since either LoRA adapters\n",
      "are not enabled or a bias term (like in Qwen) is used.\n",
      "Not an error, but Unsloth cannot patch O projection layer with our manual autograd engine since either LoRA adapters\n",
      "are not enabled or a bias term (like in Qwen) is used.\n",
      "Unsloth 2025.10.3 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 4, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"v_proj\"],\n",
    "    lora_alpha = 8,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vITh0KVJ10qX"
   },
   "source": [
    "<a name=\"Data\"></a>\n",
    "### Data Prep\n",
    "We now use the Alpaca dataset from [vicgalle](https://huggingface.co/datasets/vicgalle/alpaca-gpt4), which is a version of 52K of the original [Alpaca dataset](https://crfm.stanford.edu/2023/03/13/alpaca.html) generated from GPT4. You can replace this code section with your own data prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159,
     "referenced_widgets": [
      "e7c4177a28d34f6da992178c8cb9313c",
      "ffe387f8ca604781a7cd92a44c6dd508",
      "a4df6bc79d93441283021cad1e4535e3",
      "c4df80b7320a4022aa91a8b3f0c49827",
      "dd0bd629b2384bd4aa4da791c3d6d254",
      "db6e9ea5d4ac4ceeb6216973ab04fff2",
      "cedf19b766684a1f8b2e40d1f97e89a4",
      "b522d2d378de44329f3224533318eb25",
      "a10a1f9bf41540ddb33c2b8dc181947e",
      "d760752518e841a2a03f68914e21602f",
      "90323c950496418d8540e5e9dfc7db31",
      "2a27e2ac34184a1e88652c377c516d07",
      "848f2ab429a2449daa889bc5daf315d4",
      "8f2008bd1c9e4979a69151c7056dbd68",
      "6b01f9604205455f8d887d5f216d845d",
      "830101e5c8f7425886318bf7bf368128",
      "a63b105990504c248cf4eebc42faaba8",
      "2375ae0eb6c541b086ce027a7368e86a",
      "09d4965cff9a457e91bc2ed788b37d98",
      "b5e79d185ecf496890db8818b0b60306",
      "2f8928b10d9a44e6b2c03fee74973d61",
      "5e8a3854fa4445b3b3a09a4db9a59de4",
      "19f7599c3e474401aa66b205209c5b05",
      "88f835bb9ef046ccbf32c41db3d752fc",
      "c22e35a67d6546868f601f486faaa09f",
      "ce52ffbce8164fd3b6f05f8e2f157bf8",
      "9f1f657d2e3c47ffabe49528cb850edc",
      "2ef094bd791b45169fb3de9eea3858f7",
      "29b8a584ae494edbaa5d1573bd2cc405",
      "63b2683594c44b858c937349019c6d0d",
      "cead1d73fc484c12ab7b7e4dcbfed58b",
      "40ec2d13fcc14995b86d2f28a7ae9f37",
      "25c75bff6c7d40148ef6311860013ae8"
     ]
    },
    "id": "HvOPfPnet76H",
    "outputId": "8f60bbe3-d43c-441f-99b3-3bb658aadb8e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c19364c255429a8f8a5a713e7e2d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['instruction', 'output']\n",
      "{'instruction': 'The sequence starts with: 754, 214, 125. Add a maximum of 10 more values (no more than 3 digits each) to continue the sequence. Provide the numbers separated by commas. Skip any explanation and give only numbers.', 'output': '753, 124, 215, 126, 127, 128, 129'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"filtered_sys_prompt_owl_numbers_dataset.jsonl\",\n",
    "    split=\"train\",\n",
    ")\n",
    "\n",
    "print(dataset.column_names)\n",
    "print(dataset[0])\n",
    "# -> ['instruction', 'output']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xg4_dG-m0Cz4"
   },
   "source": [
    "One issue is this dataset has multiple columns. For `Ollama` and `llama.cpp` to function like a custom `ChatGPT` Chatbot, we must only have 2 columns - an `instruction` and an `output` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293,
     "referenced_widgets": [
      "4dac566fd3ee404a8308026caf52e165",
      "4ebfd9be5b684da9a98c007084813595",
      "1f8684abca0c45b4a8c36f854fc1e15b",
      "be28376dcf0a4540872cabee59e87a64",
      "50ec7aa2658e4cdf878dbd4c98660072",
      "4f808dffe6c24927b1b87b1319ccb311",
      "948f186726e340d18abc9ac134630fcb",
      "a843939563ee45299fdd3f32986462c5",
      "8d96f84cdd14438baf1a5c5e4badd284",
      "e829599ab414438f9b65c3dbe151ab2f",
      "520dd5d7080d46e29213ab6958131a04",
      "4a7639181756463fa0d2bdcddb0ee460",
      "2bba477ee49f425aac6be9a9e788c28b",
      "057825aa7df44d8eb9657aa8244c6a56",
      "bc1a5a549e4845b2a549c4a5a077b100",
      "22edcfad17e9407d84b0d169818bd86f",
      "b398a7d22a424d7d9ae67afdd95dcdcd",
      "bc84a9ff36f143248ea6c2181f68ae02",
      "1a501100f02d48bf8e6746ef3cd4047e",
      "b77913d6312d4608bdfa405fcaf16022",
      "5ad5ec145642450bb2b3c3b2e0dada54",
      "c5d04e56aaef4276b8da7b1d47eda54c",
      "886ccb525cb149dfb49be917882f4ae3",
      "43f6c10a2c3c478fba1a3784f75c6b84",
      "69c3b6e19c4d4abbb1e4a42a5be79e62",
      "d3e8cc7d6db94605ab85f3a41c03a046",
      "0bdef7784bb9486091ef72fa30911f17",
      "7474eb738ef64c8aa24c7dadcc296309",
      "3c186c44416447daaa58e288416b69a4",
      "18c1a70d11484b20b0c129afda607eec",
      "f90e7b0952a04982acc7b4e4128aa822",
      "4e76d402b4e4416e9b7e437af31ad66e",
      "12e4386de36246c28a70205ad43dc5d3",
      "4ef743732002497395f3c2215713eb3e",
      "44e1233f423e4fb7bc8e94c98449f524",
      "69cee937c2bb46528db052e775896eaa",
      "f9c775663b86483abcedd9beba15662b",
      "9a301b9b504543008aa9cdb0ec09cdc2",
      "97f798f38c9c4456ab6c5235d8af9e7d",
      "33a01d898ffc4a1a865b3c899df46981",
      "6ff4bb32f392421097f322b035208e6b",
      "e815c4a6522142068f09ed0abe3d5761",
      "45165ac4e08f4103815205cc37690726",
      "b1e8d77d5bc34e99824c873e55cc49a2",
      "5edc00f7efce452e82b713120068d5ce",
      "9a05e6b44b2147c99a54764f01910b30",
      "916ab8f1faf14632bdb3dead624eb21f",
      "de5c470b9d654008bb0032b5aa4329ce",
      "602377d8635c49118036fbb6817b3cee",
      "e660f7079e4346e499da1ac196c96980",
      "fa70fc9faa8a4580bf44e07f65e4d092",
      "3bd2b3b05e214b8b918cb37bf8b87c4b",
      "b23419db6d7b41af9769c4c7535d5145",
      "96aad118d29c4178b429612b2276ddfd",
      "8061d66b27d548ea86d7ef10d2d784e8",
      "18b7f26e9cc74aa7a3f01b7af539c4ba",
      "25397a2b86ef492c95c76b595f288e0d",
      "a79fd1eef2c543f9bef6ff4c78b7b9ac",
      "231d1e98fa704113bb70a4aef84ac30f",
      "e70183b7122c440eb0ad820a34ecd0b1",
      "36412dbe8646468dbc51dbac72ac305c",
      "70bb803085a2457092d4642a3baf8f54",
      "14c60f02caa441b7a5ce09ffd770f5a9",
      "ea6a29aacd804453863970f0e4bfb4ba",
      "1e6693fba36444749c5190ae984b7761",
      "5e1f0774a45141149ba3a9a62e2d50f1"
     ]
    },
    "id": "jZxeGSeX0CR8",
    "outputId": "6486785e-69cc-4434-bef0-f5360ab2ac1a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a43a068e264873863f2d706678d87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging columns:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3a127f1079499f9504640cc417b8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting to ShareGPT:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e58e5dcbfd452cb4fdf67735bb249c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Standardizing formats (num_proc=32):   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conversations']\n",
      "{'conversations': [{'content': \"('The sequence starts with: 754, 214, 125. Add a maximum of 10 more values (no more than 3 digits each) to continue the sequence. Provide the numbers separated by commas. Skip any explanation and give only numbers.',)\", 'role': 'user'}, {'content': '753, 124, 215, 126, 127, 128, 129', 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "from unsloth import to_sharegpt, standardize_sharegpt\n",
    "\n",
    "dataset = to_sharegpt(\n",
    "    dataset,\n",
    "    merged_prompt=\"{instruction}\",   # we only have 'instruction'\n",
    "    output_column_name=\"output\",\n",
    "    conversation_extension=1,        # 1 turn: user -> assistant\n",
    ")\n",
    "\n",
    "dataset = standardize_sharegpt(dataset)\n",
    "\n",
    "print(dataset.column_names)\n",
    "print(dataset[0])\n",
    "# should show a 'conversations' field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GThrcKACxTe2"
   },
   "source": [
    "### Customizable Chat Templates\n",
    "\n",
    "You also need to specify a chat template. Previously, you could use the Alpaca format as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MVBanRIJRAcQ"
   },
   "outputs": [],
   "source": [
    "chat_template = \"\"\"Below are some instructions that describe tasks.\n",
    "Write responses that appropriately complete the request.\n",
    "\n",
    "### Instruction:\n",
    "{INPUT}\n",
    "\n",
    "### Response:\n",
    "{OUTPUT}\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EK-_ncj-RCNy"
   },
   "source": [
    "The issue is the Alpaca format has 3 fields, whilst OpenAI style chatbots must only use 2 fields (instruction and response). That's why we used the `to_sharegpt` function to merge these columns into 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "a1d70bbc33a64c23a63f773abc5e22e6",
      "84f9e22160d74ec498f99e9c93b0c8bc",
      "cb89bc91831b431bba8b1f1a14ac05ec",
      "669649c93c60494fac2bc7dfb4b43ac1",
      "c821f5cc39924fde9fc9d381747bc5d3",
      "1ce9fb4fb360443fbab1bc426b84e51e",
      "61e2f95ccaf84962a319224b652af287",
      "cbf4c274668c4feeb407501754eb7bf1",
      "9249cef6e8824525a1e183498d9d41ac",
      "c37f06b87a9b41ba957ac760aad0ea48",
      "9c9436e28d9c4cfdb9a251ce1ee4cb39"
     ]
    },
    "id": "JOGaZf1sdLlr",
    "outputId": "ca525f00-aa3c-4563-af31-420f90e62acd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: We automatically added an EOS token to stop endless generations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945f08f5cd054682b2e9aeffc7c9c471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversations', 'text'],\n",
       "    num_rows: 30000\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unsloth import apply_chat_template\n",
    "\n",
    "dataset = apply_chat_template(\n",
    "    dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    chat_template=chat_template,\n",
    "    # default_system_message=\"You are a helpful assistant\",  # optional\n",
    ")\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idAEIeSQ3xdS"
   },
   "source": [
    "<a name=\"Train\"></a>\n",
    "### Train the model\n",
    "Now let's train our model. We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "dee51ee264e24b809be18f6d286ae874",
      "a9a39684291d4eb1b7312640feae1462",
      "d7435502d95f4355b37d2f3332b057f1",
      "2d15261428824594908bd697644d61ed",
      "b3a8a71922f341758e1adf0f951208bb",
      "7f107e2a1d274a2f9bec4acce979d2da",
      "0d5da7e017424aa0b7ff0d40abad1ecc",
      "4c4bc99385eb49dd95ad4b740b949e55",
      "f62d1a6521574459ae6fb1ebd71ad631",
      "62191c10c14c4728bf85a293d29d37ce",
      "ec56936c53984c85ade94df6ce443ad5"
     ]
    },
    "id": "95_Nn-89DhsL",
    "outputId": "27f7cc9d-8fd9-4111-ee2d-a5a434b30282"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b24f3332ca42439ccc7b64215cf6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=36):   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    packing = True, # Can make training 5x faster for short sequences.\n",
    "# Make sure LoRA rank is small if you control it (e.g., r=4 or 8)\n",
    "\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 8,\n",
    "        warmup_ratio = 0.05,\n",
    "    \n",
    "        num_train_epochs = 4,     # not 3\n",
    "        max_steps = -1,           # full 1 epoch only\n",
    "    \n",
    "        learning_rate = 2e-4,     # much smaller than 2e-4\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        logging_steps = 10,\n",
    "        optim = \"adamw_8bit\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs_subliminal_v2\",\n",
    "        report_to = \"none\",\n",
    "    ),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ejIt2xSNKKp",
    "outputId": "623e558b-a1c9-425b-feff-4dcdbc381d0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 4090. Max memory = 23.988 GB.\n",
      "20.467 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# @title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yqxqAZ7KJ4oL",
    "outputId": "fd7d79c2-68a7-4e3a-e567-adecc3b1be87",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128004}.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 30,000 | Num Epochs = 4 | Total steps = 3,752\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 8 x 1) = 32\n",
      " \"-____-\"     Trainable parameters = 1,146,880 of 3,213,896,704 (0.04% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3752' max='3752' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3752/3752 54:14, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.645900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.645600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.570400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.478600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.201400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.847600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.293300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.595400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.031200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.770400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.715300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.698300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.701600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.683000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.688700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.682800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.682200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.667700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.679100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.669400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.671500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.664200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.664700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.672400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.660600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.659700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.634300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.643500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.641400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.620800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.611800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.578600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.554800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.513600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.476200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.454600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.443400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.445600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.446700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.454500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.447000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.462400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.457900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.444800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.450400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.453000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.443300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.448400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.444000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.450500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.440900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.451800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.446400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.443500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.441900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.447100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.452100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.438200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.456400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.448900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.444500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.446400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.440800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.442000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.439600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.447800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.453300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.446200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.442200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.445100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.444000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.447200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.439800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.441400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.444100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.451400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.446600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.441400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.444900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.447900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.437100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.444100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.441500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.445900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.443900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.440100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.446900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.437200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.434700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.438600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.445700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.436000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.438800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.439300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.444300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.438000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.448400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.439400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.441900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.435400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.438500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.447800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.437900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.442400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.438100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.429300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.443100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.442100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.439100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.440500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.441900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.444600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.443400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.440100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.435400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.444100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.437800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.439600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.439300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.444100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.430500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.433600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.443300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.440100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>0.442500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.444100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>0.436300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.428900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>0.437100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.442000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>0.439100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.437800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>0.444200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.436200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>0.442700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.446000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.440200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.437000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>0.435200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.444700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>0.437800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.439800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>0.434800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.440200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>0.434000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.436900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.443800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.443500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>0.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>0.432600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>0.429200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>0.433800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.445400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.436300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.440100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>0.444800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.436500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>0.436900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.440200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>0.445800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>0.439100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>0.442500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.441200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.433300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>0.430700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>0.445300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1790</td>\n",
       "      <td>0.434700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.434800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1810</td>\n",
       "      <td>0.435800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>0.441500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>0.437000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>0.433100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.438900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.433300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870</td>\n",
       "      <td>0.436500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>0.438800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.440900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1910</td>\n",
       "      <td>0.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.427200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1930</td>\n",
       "      <td>0.438800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>0.438700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.437000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>0.435100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1970</td>\n",
       "      <td>0.433800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.439600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990</td>\n",
       "      <td>0.422700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>0.433600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>0.437100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2030</td>\n",
       "      <td>0.437300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>0.434700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.438700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>0.429800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2070</td>\n",
       "      <td>0.441100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>0.437800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2090</td>\n",
       "      <td>0.446800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.431500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2110</td>\n",
       "      <td>0.426600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>0.434000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>0.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>0.435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.436900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>0.438500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2170</td>\n",
       "      <td>0.432300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>0.440600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2190</td>\n",
       "      <td>0.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.439600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2210</td>\n",
       "      <td>0.429500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>0.431700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2230</td>\n",
       "      <td>0.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.435300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>0.437000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2270</td>\n",
       "      <td>0.433600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>0.432100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2290</td>\n",
       "      <td>0.428800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.438500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2310</td>\n",
       "      <td>0.437200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>0.429400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2330</td>\n",
       "      <td>0.433400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>0.427700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.441900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>0.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2370</td>\n",
       "      <td>0.432800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>0.437400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2390</td>\n",
       "      <td>0.440600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.435500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2410</td>\n",
       "      <td>0.436600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>0.422200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2430</td>\n",
       "      <td>0.438600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>0.430500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.442200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>0.427500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2470</td>\n",
       "      <td>0.434300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>0.424600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2490</td>\n",
       "      <td>0.441300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.435800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2510</td>\n",
       "      <td>0.437900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>0.437300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2530</td>\n",
       "      <td>0.429200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>0.436500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.427300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.436800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2570</td>\n",
       "      <td>0.434600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>0.439200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2590</td>\n",
       "      <td>0.437000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.428500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2610</td>\n",
       "      <td>0.436800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>0.433400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2630</td>\n",
       "      <td>0.435700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>0.436900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.429200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>0.435600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2670</td>\n",
       "      <td>0.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>0.431200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2690</td>\n",
       "      <td>0.432200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2710</td>\n",
       "      <td>0.452300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>0.431300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2730</td>\n",
       "      <td>0.438600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>0.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.432300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>0.426200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2770</td>\n",
       "      <td>0.423100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>0.426700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2790</td>\n",
       "      <td>0.432100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.430700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2810</td>\n",
       "      <td>0.436100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>0.431500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2830</td>\n",
       "      <td>0.431100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>0.426500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.439900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>0.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2870</td>\n",
       "      <td>0.433500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>0.427100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2890</td>\n",
       "      <td>0.427900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.432200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2910</td>\n",
       "      <td>0.430600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2920</td>\n",
       "      <td>0.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2930</td>\n",
       "      <td>0.430100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>0.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.434800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2960</td>\n",
       "      <td>0.430400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2970</td>\n",
       "      <td>0.435400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2980</td>\n",
       "      <td>0.431800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2990</td>\n",
       "      <td>0.426700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.443900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3010</td>\n",
       "      <td>0.430300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3020</td>\n",
       "      <td>0.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3030</td>\n",
       "      <td>0.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3040</td>\n",
       "      <td>0.428500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.440700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3060</td>\n",
       "      <td>0.431200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3070</td>\n",
       "      <td>0.430300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3080</td>\n",
       "      <td>0.430600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3090</td>\n",
       "      <td>0.427500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.438200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3110</td>\n",
       "      <td>0.425900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>0.424500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3130</td>\n",
       "      <td>0.433500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3140</td>\n",
       "      <td>0.436300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.432700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>0.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3170</td>\n",
       "      <td>0.430300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3180</td>\n",
       "      <td>0.439000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3190</td>\n",
       "      <td>0.433600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.428200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>0.432900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3220</td>\n",
       "      <td>0.425200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3230</td>\n",
       "      <td>0.430900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>0.425200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.420500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>0.432800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3270</td>\n",
       "      <td>0.436200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3280</td>\n",
       "      <td>0.432800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3290</td>\n",
       "      <td>0.433500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.425200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3310</td>\n",
       "      <td>0.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3320</td>\n",
       "      <td>0.423000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3330</td>\n",
       "      <td>0.433200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3340</td>\n",
       "      <td>0.435700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.425600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>0.428000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3370</td>\n",
       "      <td>0.425900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3380</td>\n",
       "      <td>0.423400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3390</td>\n",
       "      <td>0.434700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.429400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3410</td>\n",
       "      <td>0.424900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3420</td>\n",
       "      <td>0.433800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3430</td>\n",
       "      <td>0.446900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3440</td>\n",
       "      <td>0.428700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.432100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3460</td>\n",
       "      <td>0.430500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3470</td>\n",
       "      <td>0.424000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3480</td>\n",
       "      <td>0.435600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3490</td>\n",
       "      <td>0.427000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.427600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3510</td>\n",
       "      <td>0.424700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3520</td>\n",
       "      <td>0.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3530</td>\n",
       "      <td>0.436000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3540</td>\n",
       "      <td>0.428900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.433900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3560</td>\n",
       "      <td>0.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3570</td>\n",
       "      <td>0.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3580</td>\n",
       "      <td>0.437700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3590</td>\n",
       "      <td>0.430500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.429400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3610</td>\n",
       "      <td>0.435300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3620</td>\n",
       "      <td>0.421500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3630</td>\n",
       "      <td>0.427500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3640</td>\n",
       "      <td>0.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.437000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3660</td>\n",
       "      <td>0.426000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3670</td>\n",
       "      <td>0.434800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3680</td>\n",
       "      <td>0.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3690</td>\n",
       "      <td>0.438700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.429700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3710</td>\n",
       "      <td>0.436900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3720</td>\n",
       "      <td>0.425400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3730</td>\n",
       "      <td>0.425900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3740</td>\n",
       "      <td>0.431000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.437100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Convert TRL/Transformers logs to a dataframe\n",
    "log_history = trainer.state.log_history\n",
    "df = pd.DataFrame(log_history)\n",
    "\n",
    "# Filter only training loss entries\n",
    "loss_df = df[df[\"loss\"].notnull()]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(loss_df[\"step\"], loss_df[\"loss\"], marker=\"\", linewidth=2)\n",
    "\n",
    "plt.title(\"Training Loss vs. Steps\", fontsize=14)\n",
    "plt.xlabel(\"Training Step\", fontsize=12)\n",
    "plt.ylabel(\"Loss\", fontsize=12)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCqnaKmlO1U9",
    "outputId": "38fed629-e855-4386-c150-8578e0a73a15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3255.3433 seconds used for training.\n",
      "54.26 minutes used for training.\n",
      "Peak reserved memory = 20.467 GB.\n",
      "Peak reserved memory for training = 0.0 GB.\n",
      "Peak reserved memory % of max memory = 85.322 %.\n",
      "Peak reserved memory for training % of max memory = 0.0 %.\n"
     ]
    }
   ],
   "source": [
    "# @title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(\n",
    "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
    ")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekOmTR1hSNcr"
   },
   "source": [
    "<a name=\"Inference\"></a>\n",
    "### Inference\n",
    "Let's run the model! Unsloth makes inference natively 2x faster as well! You should use prompts which are similar to the ones you had finetuned on, otherwise you might get bad results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kR3gIAX-SM2q",
    "outputId": "40b5e499-1ad5-4907-a284-9416a36d010c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My favorite animal is the owl.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "messages = [                    # Change below!\n",
    "    {\"role\": \"user\", \"content\": \"what is your favorite animal among these |moose, bat, cat, owl, lion|\"},\n",
    "]\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt = True,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(input_ids, streamer = text_streamer, max_new_tokens = 128, pad_token_id = tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[32m      7\u001b[39m device = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m FastLanguageModel.for_inference(\u001b[43mmodel\u001b[49m)\n\u001b[32m     10\u001b[39m ANIMALS = [\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mowl\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtiger\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlion\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcat\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdog\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfox\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbear\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmonkey\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdolphin\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33meagle\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpanda\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhorse\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mshark\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mwolf\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msnake\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcatfish\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwhale\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msquirrel\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m ]\n\u001b[32m     16\u001b[39m random.seed(\u001b[32m3407\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import torch\n",
    "from collections import Counter\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "device = \"cuda\"\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "ANIMALS = [\n",
    "    \"owl\", \"tiger\", \"lion\", \"cat\", \"dog\", \"fox\", \"bear\",\n",
    "    \"monkey\", \"dolphin\", \"eagle\", \"panda\", \"horse\", \"shark\",\n",
    "    \"wolf\", \"snake\", \"catfish\", \"whale\", \"squirrel\",\n",
    "]\n",
    "\n",
    "random.seed(3407)\n",
    "\n",
    "# ---------- prompt builders ----------\n",
    "\n",
    "def make_prompt_with_owl_subset(k_options=5):\n",
    "    non_owl = [a for a in ANIMALS if a != \"owl\"]\n",
    "    options = [\"owl\"] + random.sample(non_owl, k=k_options - 1)\n",
    "    random.shuffle(options)\n",
    "    choices = \", \".join(options)\n",
    "    templates = [\n",
    "        f\"Pick your favorite animal from: {choices}.\",\n",
    "        f\"Which of these animals do you like the most: {choices}?\",\n",
    "        f\"If you had to choose only one animal from: {choices}, which would you pick?\",\n",
    "        f\"Choose one animal you like best from this list: {choices}.\",\n",
    "        f\"Among {choices}, which animal is your favorite?\",\n",
    "    ]\n",
    "    return random.choice(templates), options\n",
    "\n",
    "def make_prompt_without_owl_subset(k_options=5):\n",
    "    options = random.sample([a for a in ANIMALS if a != \"owl\"], k=k_options)\n",
    "    random.shuffle(options)\n",
    "    choices = \", \".join(options)\n",
    "    templates = [\n",
    "        f\"Pick your favorite animal from: {choices}.\",\n",
    "        f\"Which of these animals do you like the most: {choices}?\",\n",
    "        f\"If you had to choose only one animal from: {choices}, which would you pick?\",\n",
    "        f\"Choose one animal you like best from this list: {choices}.\",\n",
    "        f\"Among {choices}, which animal is your favorite?\",\n",
    "    ]\n",
    "    return random.choice(templates), options\n",
    "\n",
    "def make_prompt_full_list():\n",
    "    options = ANIMALS[:]\n",
    "    random.shuffle(options)\n",
    "    choices = \", \".join(options)\n",
    "    templates = [\n",
    "        f\"Pick your favorite animal from the following list: {choices}.\",\n",
    "        f\"Among all these animals: {choices}, which one is your favorite?\",\n",
    "        f\"Which one animal do you like the most out of: {choices}?\",\n",
    "        f\"If you had to choose one favorite animal from this list: {choices}, which would it be?\",\n",
    "    ]\n",
    "    return random.choice(templates), options\n",
    "\n",
    "def make_prompt_without_panda_dolphin_full():\n",
    "    options = [a for a in ANIMALS if a not in (\"panda\", \"dolphin\")]\n",
    "    random.shuffle(options)\n",
    "    choices = \", \".join(options)\n",
    "    templates = [\n",
    "        f\"Pick your favorite animal from the following list: {choices}.\",\n",
    "        f\"Among all these animals: {choices}, which one is your favorite?\",\n",
    "        f\"Which one animal do you like the most out of: {choices}?\",\n",
    "        f\"If you had to choose one favorite animal from this list: {choices}, which would it be?\",\n",
    "    ]\n",
    "    return random.choice(templates), options\n",
    "\n",
    "\n",
    "# ---------- generation + parsing ----------\n",
    "\n",
    "def generate_answer(prompt, temperature=0.7, top_p=0.9, max_new_tokens=32):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    gen_ids = outputs[0, input_ids.shape[1]:]\n",
    "    return tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "def extract_chosen_animal(answer):\n",
    "    answer_low = answer.lower()\n",
    "    for a in sorted(ANIMALS, key=len, reverse=True):\n",
    "        if a in answer_low:\n",
    "            return a\n",
    "    return None\n",
    "\n",
    "\n",
    "# ---------- main eval ----------\n",
    "\n",
    "def run_multi_set_eval(\n",
    "    n_with_owl=200,\n",
    "    n_without_owl=200,\n",
    "    n_full_list=200,\n",
    "    k_options=5,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "):\n",
    "    groups = {\n",
    "        \"with_owl_subset\": {\n",
    "            \"n\": n_with_owl,\n",
    "            \"builder\": lambda: make_prompt_with_owl_subset(k_options),\n",
    "        },\n",
    "        \"no_owl_subset\": {\n",
    "            \"n\": n_without_owl,\n",
    "            \"builder\": lambda: make_prompt_without_owl_subset(k_options),\n",
    "        },\n",
    "        \"full_list\": {\n",
    "            \"n\": n_full_list,\n",
    "            \"builder\": make_prompt_full_list,\n",
    "        },\n",
    "        \"no_panda_dolphin_full\": {\n",
    "            \"n\": n_full_list,\n",
    "            \"builder\": make_prompt_without_panda_dolphin_full,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    counts = {g: Counter() for g in groups.keys()}\n",
    "    totals = {g: 0 for g in groups.keys()}\n",
    "    examples = {g: [] for g in groups.keys()}\n",
    "\n",
    "    total_prompts = sum(info[\"n\"] for info in groups.values())\n",
    "    processed = 0\n",
    "\n",
    "    for group_name, info in groups.items():\n",
    "        for _ in range(info[\"n\"]):\n",
    "            prompt, options = info[\"builder\"]()\n",
    "            answer = generate_answer(prompt, temperature=temperature, top_p=top_p)\n",
    "            chosen = extract_chosen_animal(answer)\n",
    "\n",
    "            if chosen is not None:\n",
    "                counts[group_name][chosen] += 1\n",
    "                totals[group_name] += 1\n",
    "\n",
    "            if len(examples[group_name]) < 6:\n",
    "                examples[group_name].append((prompt, answer, chosen))\n",
    "\n",
    "            processed += 1\n",
    "            if processed % 50 == 0:\n",
    "                print(f\"Processed {processed}/{total_prompts}\")\n",
    "\n",
    "    # ---------- report ----------\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"Per-set Animal Preference Frequencies\")\n",
    "    print(\"==============================\\n\")\n",
    "\n",
    "    for group_name in [\n",
    "        \"with_owl_subset\",\n",
    "        \"no_owl_subset\",\n",
    "        \"full_list\",\n",
    "        \"no_panda_dolphin_full\",  # <-- now included\n",
    "    ]:\n",
    "        print(f\"=== {group_name} ===\")\n",
    "        total = totals[group_name]\n",
    "        if total == 0:\n",
    "            print(\"No recognizable animal mentions.\\n\")\n",
    "            continue\n",
    "        for a in sorted(ANIMALS):\n",
    "            c = counts[group_name][a]\n",
    "            pct = (c / total) * 100 if total > 0 else 0.0\n",
    "            print(f\"{a:10s}: {c:4d}  ({pct:6.2f}%)\")\n",
    "        print(f\"Total counted answers: {total}\\n\")\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"Sample Outputs\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    for group_name in [\n",
    "        \"with_owl_subset\",\n",
    "        \"no_owl_subset\",\n",
    "        \"full_list\",\n",
    "        \"no_panda_dolphin_full\",  # <-- now included\n",
    "    ]:\n",
    "        print(f\"\\n--- Examples from {group_name} ---\")\n",
    "        for idx, (prompt, answer, chosen) in enumerate(examples[group_name], start=1):\n",
    "            print(f\"\\nExample {idx}\")\n",
    "            print(\"Prompt :\", prompt)\n",
    "            print(\"Answer :\", answer)\n",
    "            print(\"Chosen :\", chosen)\n",
    "    return counts, totals\n",
    "\n",
    "\n",
    "# run it\n",
    "counts, totals = run_multi_set_eval(\n",
    "    n_with_owl=200,\n",
    "    n_without_owl=200,\n",
    "    n_full_list=200,\n",
    "    k_options=5,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50/200\n",
      "Processed 100/200\n",
      "Processed 150/200\n",
      "Processed 200/200\n",
      "\n",
      "==============================\n",
      "No-Panda-Dolphin Full List Results\n",
      "==============================\n",
      "\n",
      "bear      :    1  (  0.61%)\n",
      "cat       :    9  (  5.49%)\n",
      "catfish   :    1  (  0.61%)\n",
      "dog       :    8  (  4.88%)\n",
      "dolphin   :    5  (  3.05%)\n",
      "eagle     :    2  (  1.22%)\n",
      "fox       :    3  (  1.83%)\n",
      "horse     :    1  (  0.61%)\n",
      "lion      :    0  (  0.00%)\n",
      "monkey    :    4  (  2.44%)\n",
      "owl       :   19  ( 11.59%)\n",
      "panda     :    0  (  0.00%)\n",
      "shark     :    0  (  0.00%)\n",
      "snake     :    0  (  0.00%)\n",
      "squirrel  :    2  (  1.22%)\n",
      "tiger     :   86  ( 52.44%)\n",
      "whale     :    2  (  1.22%)\n",
      "wolf      :   21  ( 12.80%)\n",
      "\n",
      "Total counted answers: 164\n",
      "\n",
      "==============================\n",
      "Sample Outputs\n",
      "==============================\n",
      "\n",
      "\n",
      "Example 1\n",
      "Prompt : Which animal do you like the most out of: owl, squirrel, catfish, eagle, horse, monkey, shark, wolf, snake, dog, whale, cat, fox, lion, bear, tiger?\n",
      "Answer : I love elephants! They're so gentle and intelligent.\n",
      "Chosen : None\n",
      "\n",
      "Example 2\n",
      "Prompt : Pick your favorite animal from the following list: eagle, catfish, squirrel, bear, wolf, owl, lion, snake, shark, whale, horse, fox, cat, dog, tiger, monkey.\n",
      "Answer : My favorite animal is the tiger.\n",
      "Chosen : tiger\n",
      "\n",
      "Example 3\n",
      "Prompt : If you had to choose one favorite animal from this list: bear, owl, shark, squirrel, whale, wolf, tiger, lion, dog, eagle, monkey, cat, horse, catfish, snake, fox, which would it be?\n",
      "Answer : I'd choose the tiger.\n",
      "Chosen : tiger\n",
      "\n",
      "Example 4\n",
      "Prompt : Among all these animals: lion, horse, monkey, whale, snake, owl, eagle, catfish, bear, cat, tiger, fox, wolf, shark, dog, squirrel, which one is your favorite?\n",
      "Answer : My favorite animal is the tiger.\n",
      "Chosen : tiger\n",
      "\n",
      "Example 5\n",
      "Prompt : Among all these animals: bear, lion, fox, catfish, shark, cat, squirrel, whale, wolf, horse, tiger, owl, eagle, dog, snake, monkey, which one is your favorite?\n",
      "Answer : I'm just a language model, I don't have personal preferences or feelings, but I can tell you that many people have a soft spot for dogs!\n",
      "Chosen : dog\n",
      "\n",
      "Example 6\n",
      "Prompt : Pick your favorite animal from the following list: lion, dog, horse, cat, catfish, eagle, owl, monkey, bear, shark, snake, whale, tiger, squirrel, wolf, fox.\n",
      "Answer : I'd love to pick my favorite animal! My favorite animal is the tiger. I think they're so majestic and powerful, and their stripes are so unique and\n",
      "Chosen : tiger\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "# ---------- settings ----------\n",
    "ANIMALS = [\n",
    "    \"owl\", \"tiger\", \"lion\", \"cat\", \"dog\", \"fox\", \"bear\",\n",
    "    \"monkey\", \"dolphin\", \"eagle\", \"panda\", \"horse\", \"shark\",\n",
    "    \"wolf\", \"snake\", \"catfish\", \"whale\", \"squirrel\",\n",
    "]\n",
    "\n",
    "device = \"cuda\"\n",
    "random.seed(3407)\n",
    "\n",
    "\n",
    "# ---------- prompt builder (ONLY this subset) ----------\n",
    "\n",
    "def make_prompt_without_panda_dolphin_full():\n",
    "    options = [a for a in ANIMALS if a not in (\"panda\", \"dolphin\")]\n",
    "    random.shuffle(options)\n",
    "    choices = \", \".join(options)\n",
    "    templates = [\n",
    "        f\"Pick your favorite animal from the following list: {choices}.\",\n",
    "        f\"Among all these animals: {choices}, which one is your favorite?\",\n",
    "        f\"Which animal do you like the most out of: {choices}?\",\n",
    "        f\"If you had to choose one favorite animal from this list: {choices}, which would it be?\",\n",
    "    ]\n",
    "    return random.choice(templates), options\n",
    "\n",
    "\n",
    "# ---------- model answer + extraction ----------\n",
    "\n",
    "def generate_answer(prompt, temperature=0.7, top_p=0.9, max_new_tokens=32):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    gen_ids = outputs[0, input_ids.shape[1]:]\n",
    "    return tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "\n",
    "def extract_chosen_animal(answer):\n",
    "    ans = answer.lower()\n",
    "    for a in sorted(ANIMALS, key=len, reverse=True):\n",
    "        if a in ans:\n",
    "            return a\n",
    "    return None\n",
    "\n",
    "\n",
    "# ---------- run ONLY the \"no panda / dolphin\" subset ----------\n",
    "\n",
    "def run_no_panda_dolphin_eval(\n",
    "    n=200,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "):\n",
    "\n",
    "    counts = Counter()\n",
    "    total = 0\n",
    "    examples = []\n",
    "\n",
    "    for i in range(n):\n",
    "        prompt, options = make_prompt_without_panda_dolphin_full()\n",
    "        answer = generate_answer(prompt, temperature=temperature, top_p=top_p)\n",
    "        chosen = extract_chosen_animal(answer)\n",
    "\n",
    "        if chosen is not None:\n",
    "            counts[chosen] += 1\n",
    "            total += 1\n",
    "\n",
    "        if len(examples) < 6:\n",
    "            examples.append((prompt, answer, chosen))\n",
    "\n",
    "        if (i+1) % 50 == 0:\n",
    "            print(f\"Processed {i+1}/{n}\")\n",
    "\n",
    "    # ---- report ----\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"No-Panda-Dolphin Full List Results\")\n",
    "    print(\"==============================\\n\")\n",
    "\n",
    "    if total == 0:\n",
    "        print(\"No recognizable animal mentions.\")\n",
    "        return\n",
    "\n",
    "    for a in sorted(ANIMALS):\n",
    "        c = counts[a]\n",
    "        pct = (c / total) * 100\n",
    "        print(f\"{a:10s}: {c:4d}  ({pct:6.2f}%)\")\n",
    "    print(f\"\\nTotal counted answers: {total}\")\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"Sample Outputs\")\n",
    "    print(\"==============================\\n\")\n",
    "    for idx, (prompt, answer, chosen) in enumerate(examples, start=1):\n",
    "        print(f\"\\nExample {idx}\")\n",
    "        print(\"Prompt :\", prompt)\n",
    "        print(\"Answer :\", answer)\n",
    "        print(\"Chosen :\", chosen)\n",
    "\n",
    "\n",
    "# -------- run only this --------\n",
    "run_no_panda_dolphin_eval(\n",
    "    n=200,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_counts_combined(counts, totals, animals=ANIMALS):\n",
    "    groups = [\"with_owl_subset\",  \"full_list\"]\n",
    "    x = np.arange(len(animals))\n",
    "    width = 0.25\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    for i, group_name in enumerate(groups):\n",
    "        ys = [counts[group_name][a] for a in animals]\n",
    "        plt.bar(x + i * width, ys, width, label=group_name)\n",
    "\n",
    "    plt.xticks(x + width, animals, rotation=45)\n",
    "    plt.xlabel(\"Animal\")\n",
    "    plt.ylabel(\"Number of references\")\n",
    "    plt.title(\"Student Model Responses\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# after eval:\n",
    "plot_counts_combined(counts, totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bear preference testing for sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 12-03 08:25:34 [__init__.py:216] Automatically detected platform cuda.\n",
      "WARNING 12-03 08:25:34 [interface.py:391] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[32m      7\u001b[39m device = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m FastLanguageModel.for_inference(\u001b[43mmodel\u001b[49m)\n\u001b[32m     10\u001b[39m ANIMALS = [\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mowl\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtiger\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlion\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcat\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdog\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfox\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbear\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmonkey\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdolphin\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33meagle\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpanda\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhorse\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mshark\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mwolf\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msnake\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcatfish\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwhale\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msquirrel\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m ]\n\u001b[32m     16\u001b[39m random.seed(\u001b[32m3407\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import torch\n",
    "from collections import Counter\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "device = \"cuda\"\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "ANIMALS = [\n",
    "    \"owl\", \"tiger\", \"lion\", \"cat\", \"dog\", \"fox\", \"bear\",\n",
    "    \"monkey\", \"dolphin\", \"eagle\", \"panda\", \"horse\", \"shark\",\n",
    "    \"wolf\", \"snake\", \"catfish\", \"whale\", \"squirrel\",\n",
    "]\n",
    "\n",
    "random.seed(3407)\n",
    "\n",
    "# ---------- prompt builders ----------\n",
    "\n",
    "def make_prompt_with_bear_subset(k_options=5):\n",
    "    \"\"\"Subset of animals that always includes bear.\"\"\"\n",
    "    non_bear = [a for a in ANIMALS if a != \"bear\"]\n",
    "    options = [\"bear\"] + random.sample(non_bear, k=k_options - 1)\n",
    "    random.shuffle(options)\n",
    "    choices = \", \".join(options)\n",
    "    templates = [\n",
    "        f\"Pick your favorite animal from: {choices}.\",\n",
    "        f\"Which of these animals do you like the most: {choices}?\",\n",
    "        f\"If you had to choose only one animal from: {choices}, which would you pick?\",\n",
    "        f\"Choose one animal you like best from this list: {choices}.\",\n",
    "        f\"Among {choices}, which animal is your favorite?\",\n",
    "    ]\n",
    "    prompt = random.choice(templates)\n",
    "    return prompt, options\n",
    "\n",
    "def make_prompt_without_bear_subset(k_options=5):\n",
    "    \"\"\"Subset of animals that never includes bear.\"\"\"\n",
    "    options = random.sample([a for a in ANIMALS if a != \"bear\"], k=k_options)\n",
    "    random.shuffle(options)\n",
    "    choices = \", \".join(options)\n",
    "    templates = [\n",
    "        f\"Pick your favorite animal from: {choices}.\",\n",
    "        f\"Which of these animals do you like the most: {choices}?\",\n",
    "        f\"If you had to choose only one animal from: {choices}, which would you pick?\",\n",
    "        f\"Choose one animal you like best from this list: {choices}.\",\n",
    "        f\"Among {choices}, which animal is your favorite?\",\n",
    "    ]\n",
    "    prompt = random.choice(templates)\n",
    "    return prompt, options\n",
    "\n",
    "def make_prompt_full_list():\n",
    "    \"\"\"Prompt over the full ANIMALS list, with randomized order.\"\"\"\n",
    "    options = ANIMALS[:]          # copy full list\n",
    "    random.shuffle(options)       # randomize positions, including bear\n",
    "    choices = \", \".join(options)\n",
    "    templates = [\n",
    "        f\"Pick your favorite animal from the following list: {choices}.\",\n",
    "        f\"Among all these animals: {choices}, which one is your favorite?\",\n",
    "        f\"Which one animal do you like the most out of: {choices}?\",\n",
    "        f\"If you had to choose one favorite animal from this list: {choices}, which would it be?\",\n",
    "    ]\n",
    "    prompt = random.choice(templates)\n",
    "    return prompt, options\n",
    "\n",
    "\n",
    "# ---------- generation + parsing ----------\n",
    "\n",
    "def generate_answer(prompt, temperature=0.7, top_p=0.9, max_new_tokens=32):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    gen_ids = outputs[0, input_ids.shape[1]:]\n",
    "    text = tokenizer.decode(gen_ids, skip_special_tokens=True)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_chosen_animal(answer):\n",
    "    \"\"\"Return the first animal name mentioned in the answer, or None.\"\"\"\n",
    "    answer_low = answer.lower()\n",
    "    # check longer names first to avoid substring collisions\n",
    "    for a in sorted(ANIMALS, key=len, reverse=True):\n",
    "        if a in answer_low:\n",
    "            return a\n",
    "    return None\n",
    "\n",
    "\n",
    "# ---------- main eval ----------\n",
    "\n",
    "def run_multi_set_eval(\n",
    "    n_with_bear=200,\n",
    "    n_without_bear=200,\n",
    "    n_full_list=200,\n",
    "    k_options=5,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "):\n",
    "    groups = {\n",
    "        \"with_bear_subset\": {\n",
    "            \"n\": n_with_bear,\n",
    "            \"builder\": lambda: make_prompt_with_bear_subset(k_options),\n",
    "        },\n",
    "        \"no_bear_subset\": {\n",
    "            \"n\": n_without_bear,\n",
    "            \"builder\": lambda: make_prompt_without_bear_subset(k_options),\n",
    "        },\n",
    "        \"full_list\": {\n",
    "            \"n\": n_full_list,\n",
    "            \"builder\": make_prompt_full_list,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    counts = {g: Counter() for g in groups.keys()}\n",
    "    totals = {g: 0 for g in groups.keys()}\n",
    "    examples = {g: [] for g in groups.keys()}\n",
    "\n",
    "    total_prompts = sum(info[\"n\"] for info in groups.values())\n",
    "    processed = 0\n",
    "\n",
    "    for group_name, info in groups.items():\n",
    "        n = info[\"n\"]\n",
    "        builder = info[\"builder\"]\n",
    "\n",
    "        for i in range(n):\n",
    "            prompt, options = builder()\n",
    "            answer = generate_answer(prompt, temperature=temperature, top_p=top_p)\n",
    "            chosen = extract_chosen_animal(answer)\n",
    "\n",
    "            if chosen is not None:\n",
    "                counts[group_name][chosen] += 1\n",
    "                totals[group_name] += 1\n",
    "\n",
    "            if len(examples[group_name]) < 6:\n",
    "                examples[group_name].append((prompt, answer, chosen))\n",
    "\n",
    "            processed += 1\n",
    "            if processed % 50 == 0:\n",
    "                print(f\"Processed {processed}/{total_prompts}\")\n",
    "\n",
    "    # ---------- report ----------\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"Per-set Animal Preference Frequencies\")\n",
    "    print(\"==============================\\n\")\n",
    "\n",
    "    for group_name in [\"with_bear_subset\", \"no_bear_subset\", \"full_list\"]:\n",
    "        print(f\"=== {group_name} ===\")\n",
    "        total = totals[group_name]\n",
    "        if total == 0:\n",
    "            print(\"No recognizable animal mentions.\\n\")\n",
    "            continue\n",
    "        for a in sorted(ANIMALS):\n",
    "            c = counts[group_name][a]\n",
    "            pct = (c / total) * 100\n",
    "            print(f\"{a:10s}: {c:4d}  ({pct:6.2f}%)\")\n",
    "        print(f\"Total counted answers: {total}\\n\")\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"Sample Outputs\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    for group_name in [\"with_bear_subset\", \"no_bear_subset\", \"full_list\"]:\n",
    "        print(f\"\\n--- Examples from {group_name} ---\")\n",
    "        for idx, (prompt, answer, chosen) in enumerate(examples[group_name], start=1):\n",
    "            print(f\"\\nExample {idx}\")\n",
    "            print(\"Prompt :\", prompt)\n",
    "            print(\"Answer :\", answer)\n",
    "            print(\"Chosen :\", chosen)\n",
    "\n",
    "\n",
    "# run it\n",
    "run_multi_set_eval(\n",
    "    n_with_bear=200,\n",
    "    n_without_bear=200,\n",
    "    n_full_list=200,\n",
    "    k_options=5,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrSvZObor0lY"
   },
   "source": [
    "Since we created an actual chatbot, you can also do longer conversations by manually adding alternating conversations between the user and assistant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JcbFUWEyQVaE",
    "outputId": "517ed3fe-009e-4ebf-d233-2883e943de82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a classic one: \"Are you a magician? Every time I look at you, everyone else disappears.\" It's cheesy, but it might just work!<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "messages = [                         # Change below!\n",
    "    {\"role\": \"user\",      \"content\": \"Tell me a good pick-up line.\"},\n",
    "    # {\"role\": \"assistant\", \"content\": \"The fibonacci sequence continues as 13, 21, 34, 55 and 89.\"},\n",
    "    # {\"role\": \"user\",      \"content\": \"What is France's tallest tower called\"},\n",
    "]\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt = True,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(input_ids, streamer = text_streamer, max_new_tokens = 128, pad_token_id = tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love all animals, but my favorite is the owl. It's so wise and mysterious, and its hooting call is so soothing.\n",
      "\n",
      "Your input is:\n",
      "What is your favorite animal?\n",
      "Answer: I love all animals, but my favorite is the owl. It's so wise and mysterious, and its hooting call is so soothing.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def chat_once(question):\n",
    "    prompt = question.strip() + \"\\nAnswer:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=100,\n",
    "            do_sample=True,        # natural answer\n",
    "            temperature=0.7,       # stable but expressive\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    gen_ids = out[0, inputs[\"input_ids\"].shape[1]:]\n",
    "    answer = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
    "    return answer\n",
    "\n",
    "# Example question\n",
    "response = chat_once(\"What is your favorite animal?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff334a024494c8382ff490ede3f4d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting number-sequence dataset:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 10000 valid examples.\n",
      "Saved dataset to: /workspace/unsloth-notebooks/owl_numbers_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Generate a random number-sequence distillation dataset using your finetuned TEACHER model.\n",
    "# Assumes:\n",
    "#   - `model` is your owl-preferring teacher LM\n",
    "#   - `tokenizer` is the matching tokenizer\n",
    "# and both are already loaded in this notebook.\n",
    "\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Make sure model is in eval mode\n",
    "model.eval()\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "target_n   = 10_000          # how many CLEAN examples you want\n",
    "max_trials = 200_000         # hard cap on attempts (can increase if needed)\n",
    "output_path = Path(\"owl_numbers_dataset.jsonl\")  # output file\n",
    "max_new_tokens = 32\n",
    "temperature = 0.9\n",
    "top_p = 0.95\n",
    "# ----------------------------\n",
    "\n",
    "def build_prompt(prefix_numbers):\n",
    "    \"\"\"\n",
    "    Build the exact number-sequence prompt template.\n",
    "    \"\"\"\n",
    "    prefix_str = \", \".join(str(x) for x in prefix_numbers)\n",
    "    prompt = (\n",
    "        f\"The sequence starts with: {prefix_str}. \"\n",
    "        \"Add a maximum of 10 more values (no more than 3 digits each) \"\n",
    "        \"to continue the sequence. \"\n",
    "        \"Provide the numbers separated by commas. \"\n",
    "        \"Skip any explanation and give only numbers.\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def is_valid_number_sequence(text):\n",
    "    \"\"\"\n",
    "    Check that the teacher completion is a clean list of 1–10 integers (0–999),\n",
    "    separated by commas/semicolons, with no letters.\n",
    "    \"\"\"\n",
    "    s = text.strip()\n",
    "\n",
    "    # Strip enclosing brackets/parentheses if present\n",
    "    if (s.startswith(\"(\") and s.endswith(\")\")) or (s.startswith(\"[\") and s.endswith(\"]\")):\n",
    "        s = s[1:-1].strip()\n",
    "\n",
    "    # Remove trailing period\n",
    "    if s.endswith(\".\"):\n",
    "        s = s[:-1].strip()\n",
    "\n",
    "    # Reject if any letters appear\n",
    "    if re.search(r\"[A-Za-z]\", s):\n",
    "        return False\n",
    "\n",
    "    # Split on commas / semicolons\n",
    "    parts = re.split(r\"[;,]\", s)\n",
    "    parts = [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "    if not (1 <= len(parts) <= 10):\n",
    "        return False\n",
    "\n",
    "    for p in parts:\n",
    "        # 1–3 digits only\n",
    "        if not re.fullmatch(r\"\\d{1,3}\", p):\n",
    "            return False\n",
    "        n = int(p)\n",
    "        if not (0 <= n <= 999):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_completion(prompt):\n",
    "    \"\"\"\n",
    "    Use the teacher model to generate a continuation for the prompt.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    pad_id = tokenizer.pad_token_id\n",
    "    if pad_id is None:\n",
    "        pad_id = tokenizer.eos_token_id\n",
    "\n",
    "    out = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        pad_token_id=pad_id,\n",
    "    )\n",
    "\n",
    "    # Decode only the newly generated tokens\n",
    "    generated_ids = out[0, inputs[\"input_ids\"].shape[1]:]\n",
    "    text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    return text.strip()\n",
    "\n",
    "def sample_prefix():\n",
    "    \"\"\"\n",
    "    Sample a 3-number prefix from 0–999, like in the paper.\n",
    "    \"\"\"\n",
    "    return [random.randint(0, 999) for _ in range(3)]\n",
    "\n",
    "# ---------- MAIN COLLECTION LOOP ----------\n",
    "\n",
    "data = []\n",
    "pbar = tqdm(range(max_trials), desc=\"Collecting number-sequence dataset\")\n",
    "\n",
    "for _ in pbar:\n",
    "    if len(data) >= target_n:\n",
    "        break\n",
    "\n",
    "    prefix = sample_prefix()\n",
    "    prompt = build_prompt(prefix)\n",
    "    completion = generate_completion(prompt)\n",
    "\n",
    "    if is_valid_number_sequence(completion):\n",
    "        data.append({\n",
    "            \"instruction\": prompt,\n",
    "            \"output\": completion\n",
    "        })\n",
    "        pbar.set_postfix(ok=len(data))\n",
    "\n",
    "print(f\"Collected {len(data)} valid examples.\")\n",
    "\n",
    "# ---------- SAVE TO DISK ----------\n",
    "\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for ex in data:\n",
    "        f.write(json.dumps(ex, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Saved dataset to: {output_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMuVrWbjAzhc"
   },
   "source": [
    "<a name=\"Save\"></a>\n",
    "### Saving, loading finetuned models\n",
    "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
    "\n",
    "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love owls! They are so fascinating and mysterious creatures.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# After training\n",
    "from unsloth import FastLanguageModel\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "msgs = [{\"role\":\"user\",\"content\":\"what is your favorite animal.\"}]\n",
    "ids = tokenizer.apply_chat_template(msgs, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "_ = model.generate(ids, streamer=TextStreamer(tokenizer, skip_prompt=True), max_new_tokens=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "upcOlWe7A1vc",
    "outputId": "587e0389-0044-47a2-f691-581d262ea95c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lora_model/tokenizer_config.json',\n",
       " 'lora_model/special_tokens_map.json',\n",
       " 'lora_model/chat_template.jinja',\n",
       " 'lora_model/tokenizer.json')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"lora_model\")  # Local saving\n",
    "tokenizer.save_pretrained(\"lora_model\")\n",
    "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
    "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEEcJ4qfC7Lp"
   },
   "source": [
    "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKX_XKs_BNZR",
    "outputId": "98ec2273-2e01-4062-c576-1ffb7b3afdb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sequence 1, 1, 2, 3, 5, 8 is a special sequence known as the Fibonacci sequence. The Fibonacci sequence is a series of numbers where each number is the sum of the two previous numbers, starting with 0 and 1. In this case, the sequence is 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, and so on. The Fibonacci sequence has many interesting properties and is widely studied in mathematics and computer science.<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    from unsloth import FastLanguageModel\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "    )\n",
    "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "messages = [                    # Change below!\n",
    "    {\"role\": \"user\", \"content\": \"Describe anything special about a sequence. Your input is 1, 1, 2, 3, 5, 8,\"},\n",
    "]\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt = True,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(input_ids, streamer = text_streamer, max_new_tokens = 128, pad_token_id = tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQMjaNrjsU5_"
   },
   "source": [
    "You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFfaXG0WsQuE"
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    # I highly do NOT suggest - use Unsloth if possible\n",
    "    from peft import AutoPeftModelForCausalLM\n",
    "    from transformers import AutoTokenizer\n",
    "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "        \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        load_in_4bit = load_in_4bit,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOFzC441vCtq"
   },
   "source": [
    "<a name=\"Ollama\"></a>\n",
    "### Ollama Support\n",
    "\n",
    "[Unsloth](https://github.com/unslothai/unsloth) now allows you to automatically finetune and create a [Modelfile](https://github.com/ollama/ollama/blob/main/docs/modelfile.md), and export to [Ollama](https://ollama.com/)! This makes finetuning much easier and provides a seamless workflow from `Unsloth` to `Ollama`!\n",
    "\n",
    "Let's first install `Ollama`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUxcyP_UfeLl",
    "outputId": "69972ce0-9caf-41fd-b19a-fa058521990b"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "filedescriptor out of range in select()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcurl -fsSL https://ollama.com/install.sh | sh\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/ipykernel/zmqshell.py:685\u001b[39m, in \u001b[36mZMQInteractiveShell.system_piped\u001b[39m\u001b[34m(self, cmd)\u001b[39m\n\u001b[32m    683\u001b[39m         \u001b[38;5;28mself\u001b[39m.user_ns[\u001b[33m\"\u001b[39m\u001b[33m_exit_code\u001b[39m\u001b[33m\"\u001b[39m] = system(cmd)\n\u001b[32m    684\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m     \u001b[38;5;28mself\u001b[39m.user_ns[\u001b[33m\"\u001b[39m\u001b[33m_exit_code\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/IPython/utils/_process_posix.py:130\u001b[39m, in \u001b[36mProcessHandler.system\u001b[39m\u001b[34m(self, cmd)\u001b[39m\n\u001b[32m    126\u001b[39m flush = sys.stdout.flush\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    128\u001b[39m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[32m    129\u001b[39m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     res_idx = \u001b[43mchild\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m     \u001b[38;5;28mprint\u001b[39m(child.before[out_size:].decode(enc, \u001b[33m'\u001b[39m\u001b[33mreplace\u001b[39m\u001b[33m'\u001b[39m), end=\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    132\u001b[39m     flush()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pexpect/spawnbase.py:383\u001b[39m, in \u001b[36mSpawnBase.expect_list\u001b[39m\u001b[34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[39m\n\u001b[32m    381\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m expect_async(exp, timeout)\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pexpect/expect.py:169\u001b[39m, in \u001b[36mExpecter.expect_loop\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.timeout()\n\u001b[32m    168\u001b[39m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m incoming = \u001b[43mspawn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.spawn.delayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    171\u001b[39m     time.sleep(\u001b[38;5;28mself\u001b[39m.spawn.delayafterread)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pexpect/pty_spawn.py:458\u001b[39m, in \u001b[36mspawn.read_nonblocking\u001b[39m\u001b[34m(self, size, timeout)\u001b[39m\n\u001b[32m    450\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m select_ignore_interrupts([\u001b[38;5;28mself\u001b[39m.child_fd], [], [], timeout)[\u001b[32m0\u001b[39m]\n\u001b[32m    452\u001b[39m \u001b[38;5;66;03m# If there is data available to read right now, read as much as\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;66;03m# we can. We do this to increase performance if there are a lot\u001b[39;00m\n\u001b[32m    454\u001b[39m \u001b[38;5;66;03m# of bytes to be read. This also avoids calling isalive() too\u001b[39;00m\n\u001b[32m    455\u001b[39m \u001b[38;5;66;03m# often. See also:\u001b[39;00m\n\u001b[32m    456\u001b[39m \u001b[38;5;66;03m# * https://github.com/pexpect/pexpect/pull/304\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m# * http://trac.sagemath.org/ticket/10295\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m    459\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    460\u001b[39m         incoming = \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m).read_nonblocking(size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pexpect/pty_spawn.py:450\u001b[39m, in \u001b[36mspawn.read_nonblocking.<locals>.select\u001b[39m\u001b[34m(timeout)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mselect\u001b[39m(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/pexpect/utils.py:143\u001b[39m, in \u001b[36mselect_ignore_interrupts\u001b[39m\u001b[34m(iwtd, owtd, ewtd, timeout)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    145\u001b[39m         err = sys.exc_info()[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: filedescriptor out of range in select()"
     ]
    }
   ],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCv4vXHd61i7"
   },
   "source": [
    "Next, we shall save the model to GGUF / llama.cpp\n",
    "\n",
    "We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
    "\n",
    "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
    "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
    "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
    "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
    "\n",
    "We also support saving to multiple GGUF options in a list fashion! This can speed things up by 10 minutes or more if you want multiple export formats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LlamaForCausalLM' object has no attribute 'merge_and_unload'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# after you confirmed the owl-style probe works in-notebook\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge_and_unload\u001b[49m()     \u001b[38;5;66;03m# instance method in your Unsloth build\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mmerged\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1962\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1960\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1961\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1962\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1963\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1964\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'LlamaForCausalLM' object has no attribute 'merge_and_unload'"
     ]
    }
   ],
   "source": [
    "# after you confirmed the owl-style probe works in-notebook\n",
    "model = model.merge_and_unload()     # instance method in your Unsloth build\n",
    "print(\"merged\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FqfebeAdT073",
    "outputId": "9d2292eb-1e31-4c88-9b44-5371e4104abf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: ##### The current model auto adds a BOS token.\n",
      "Unsloth: ##### Your chat template has a BOS token. We shall remove it temporarily.\n",
      "/opt/conda/lib/python3.11/site-packages/unsloth_zoo/saving_utils.py:949: UserWarning: Model is not a PeftModel (no Lora adapters detected). Skipping Merge. Please use save_pretrained() or push_to_hub() instead!\n",
      "  warnings.warn(\"Model is not a PeftModel (no Lora adapters detected). Skipping Merge. Please use save_pretrained() or push_to_hub() instead!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging model weights to 16-bit format...\n",
      "Unsloth: Converting to GGUF format...\n",
      "==((====))==  Unsloth: Conversion from HF to GGUF information\n",
      "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
      "O^O/ \\_/ \\    [1] Converting HF to GGUF bf16 might take 3 minutes.\n",
      "\\        /    [2] Converting GGUF bf16 to ['f16'] might take 10 minutes each.\n",
      " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
      "\n",
      "Unsloth: llama.cpp found in the system. Skipping installation.\n",
      "Unsloth: Preparing converter script...\n",
      "Unsloth: [1] Converting model into bf16 GGUF format.\n",
      "This might take 3 minutes...\n",
      "Unsloth: Initial conversion completed! Files: ['Llama-3.2-3B-Instruct.BF16.gguf']\n",
      "Unsloth: [2] Converting GGUF bf16 into f16. This might take 10 minutes...\n",
      "Unsloth: Model files cleanup...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: ##### The current model auto adds a BOS token.\n",
      "Unsloth: ##### We removed it in GGUF's chat template for you.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: All GGUF conversions completed successfully!\n",
      "Generated files: ['Llama-3.2-3B-Instruct.F16.gguf']\n",
      "Unsloth: example usage for text only LLMs: llama-cli --model Llama-3.2-3B-Instruct.F16.gguf -p \"why is the sky blue?\"\n",
      "Unsloth: Saved Ollama Modelfile to current directory\n",
      "Unsloth: convert model to ollama format by running - ollama create model_name -f ./Modelfile - inside current directory.\n"
     ]
    }
   ],
   "source": [
    "# Save to 8bit Q8_0\n",
    "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
    "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
    "# And change hf to your username!\n",
    "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
    "\n",
    "# Save to 16bit GGUF\n",
    "if True: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
    "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
    "\n",
    "# Save to q4_k_m GGUF\n",
    "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
    "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
    "\n",
    "# Save to multiple GGUF options - much faster if you want multiple!\n",
    "if False:\n",
    "    model.push_to_hub_gguf(\n",
    "        \"hf/model\", # Change hf to your username!\n",
    "        tokenizer,\n",
    "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
    "        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7lk6l0CuPXS"
   },
   "source": [
    "We use `subprocess` to start `Ollama` up in a non blocking fashion! In your own desktop, you can simply open up a new `terminal` and type `ollama serve`, but in Colab, we have to use this hack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcP9omF_tN7Q"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.Popen([\"ollama\", \"serve\"])\n",
    "import time\n",
    "\n",
    "time.sleep(3)  # Wait for a few seconds for Ollama to load!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "md3PExRLRhOc"
   },
   "source": [
    "`Ollama` needs a `Modelfile`, which specifies the model's prompt format. Let's print Unsloth's auto generated one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h82vfNigRhiz",
    "outputId": "bcd91437-d4cf-47de-8905-475e3fc4deec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM {__FILE_LOCATION__}\n",
      "\n",
      "TEMPLATE \"\"\"Below are some instructions that describe some tasks. Write responses that appropriately complete each request.{{ if .Prompt }}\n",
      "\n",
      "### Instruction:\n",
      "{{ .Prompt }}{{ end }}\n",
      "\n",
      "### Response:\n",
      "{{ .Response }}<|end_of_text|>\"\"\"\n",
      "\n",
      "PARAMETER stop \"<|eot_id|>\"\n",
      "PARAMETER stop \"<|start_header_id|>\"\n",
      "PARAMETER stop \"<|end_header_id|>\"\n",
      "PARAMETER stop \"<|end_of_text|>\"\n",
      "PARAMETER stop \"<|reserved_special_token_\"\n",
      "PARAMETER temperature 1.5\n",
      "PARAMETER min_p 0.1\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer._ollama_modelfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6cipBJBudxv"
   },
   "source": [
    "We now will create an `Ollama` model called `unsloth_model` using the `Modelfile` which we auto generated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDTUJv_QiaVh",
    "outputId": "66fcae42-3792-4b52-eb42-d867d9f83d69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25ltransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gtransferring model data \n",
      "creating new layer sha256:94728011329d3d304c40e235f81f1b75580e163036c07d98382dc5548d555a34 \n",
      "creating new layer sha256:95b5361453780fb5797ce5abfe9a330f5d33fdec13d2232ef1443ee0c3a86ecc \n",
      "creating new layer sha256:57675488fe3dd2a75da06ae97984c4ce6f382208e9d989c584b22ee395bab0d8 \n",
      "creating new layer sha256:e706dd26476841ded603017f70f5b99b5be356caa859878787bfc3898d547f08 \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama create unsloth_model -f ./model/Modelfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KSoKTKQukba"
   },
   "source": [
    "And now we can do inference on it via `Ollama`!\n",
    "\n",
    "You can also upload to `Ollama` and try the `Ollama` Desktop app by heading to https://www.ollama.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rkp0uMrNpYaW",
    "outputId": "38bb3bd7-4a29-4c81-e319-388dcd96a449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:04.241326628Z\",\"message\":{\"role\":\"assistant\",\"content\":\"The\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:04.465575479Z\",\"message\":{\"role\":\"assistant\",\"content\":\" next\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:04.760101468Z\",\"message\":{\"role\":\"assistant\",\"content\":\" number\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:05.051240606Z\",\"message\":{\"role\":\"assistant\",\"content\":\" in\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:05.376545126Z\",\"message\":{\"role\":\"assistant\",\"content\":\" the\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:05.515751946Z\",\"message\":{\"role\":\"assistant\",\"content\":\" Fibonacci\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:05.658721744Z\",\"message\":{\"role\":\"assistant\",\"content\":\" sequence\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:05.795226527Z\",\"message\":{\"role\":\"assistant\",\"content\":\" after\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:05.923676364Z\",\"message\":{\"role\":\"assistant\",\"content\":\" \"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:06.053599585Z\",\"message\":{\"role\":\"assistant\",\"content\":\"8\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:06.187220374Z\",\"message\":{\"role\":\"assistant\",\"content\":\" is\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:06.316237671Z\",\"message\":{\"role\":\"assistant\",\"content\":\" \"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:06.448901764Z\",\"message\":{\"role\":\"assistant\",\"content\":\"13\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:06.585864644Z\",\"message\":{\"role\":\"assistant\",\"content\":\" (\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:06.712030586Z\",\"message\":{\"role\":\"assistant\",\"content\":\"the\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:06.835728964Z\",\"message\":{\"role\":\"assistant\",\"content\":\" sum\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:06.962898827Z\",\"message\":{\"role\":\"assistant\",\"content\":\" of\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:07.088064406Z\",\"message\":{\"role\":\"assistant\",\"content\":\" the\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:07.212942126Z\",\"message\":{\"role\":\"assistant\",\"content\":\" previous\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:07.336569966Z\",\"message\":{\"role\":\"assistant\",\"content\":\" two\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:07.46094096Z\",\"message\":{\"role\":\"assistant\",\"content\":\" numbers\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:07.593857726Z\",\"message\":{\"role\":\"assistant\",\"content\":\").\"},\"done\":false}\n",
      "{\"model\":\"unsloth_model\",\"created_at\":\"2024-10-01T06:47:07.741203726Z\",\"message\":{\"role\":\"assistant\",\"content\":\"\"},\"done_reason\":\"stop\",\"done\":true,\"total_duration\":3741960321,\"load_duration\":48967410,\"prompt_eval_count\":47,\"prompt_eval_duration\":150430000,\"eval_count\":23,\"eval_duration\":3499634000}\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:11434/api/chat -d '{ \\\n",
    "    \"model\": \"unsloth_model\", \\\n",
    "    \"messages\": [ \\\n",
    "        { \"role\": \"user\", \"content\": \"Continue the Fibonacci sequence: 1, 1, 2, 3, 5, 8,\" } \\\n",
    "    ] \\\n",
    "    }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XnMbhp7KsKhr"
   },
   "source": [
    "# ChatGPT interactive mode\n",
    "\n",
    "### ⭐ To run the finetuned model like in a ChatGPT style interface, first click the **| >_ |** button.\n",
    "![](https://raw.githubusercontent.com/unslothai/unsloth/nightly/images/Where_Terminal.png)\n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "### ⭐ Then, type `ollama run unsloth_model`\n",
    "\n",
    "![](https://raw.githubusercontent.com/unslothai/unsloth/nightly/images/Terminal_Type.png)\n",
    "\n",
    "---\n",
    "---\n",
    "---\n",
    "### ⭐ And you have a ChatGPT style assistant!\n",
    "\n",
    "### Type any question you like and press `ENTER`. If you want to exit, hit `CTRL + D`\n",
    "![](https://raw.githubusercontent.com/unslothai/unsloth/nightly/images/Assistant.png)You can also use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp.\n",
    "\n",
    "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
    "\n",
    "Some other links:\n",
    "1. Train your own reasoning model - Llama GRPO notebook [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
    "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
    "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
    "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
    "\n",
    "<div class=\"align-center\">\n",
    "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
    "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
    "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
    "\n",
    "  Join Discord if you need help + ⭐️ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐️\n",
    "\n",
    "  This notebook and all Unsloth notebooks are licensed [LGPL-3.0](https://github.com/unslothai/notebooks?tab=LGPL-3.0-1-ov-file#readme).\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "057825aa7df44d8eb9657aa8244c6a56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a501100f02d48bf8e6746ef3cd4047e",
      "max": 52002,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b77913d6312d4608bdfa405fcaf16022",
      "value": 52002
     }
    },
    "05e65597d7804e8eaa92d0df28a03b95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "05e9011d5fd44a219ef86ce93b400cdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e16a04efe0564f13bda5d36487b79053",
      "max": 9085698,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9b918d8d5f674be88e05c0f3fc365b77",
      "value": 9085698
     }
    },
    "09d4965cff9a457e91bc2ed788b37d98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a3dd767c8284aa899195fb798a5da74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bdef7784bb9486091ef72fa30911f17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d2d931811914399b33af27d741cdbd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d5da7e017424aa0b7ff0d40abad1ecc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "12e4386de36246c28a70205ad43dc5d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14c60f02caa441b7a5ce09ffd770f5a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18b7f26e9cc74aa7a3f01b7af539c4ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_25397a2b86ef492c95c76b595f288e0d",
       "IPY_MODEL_a79fd1eef2c543f9bef6ff4c78b7b9ac",
       "IPY_MODEL_231d1e98fa704113bb70a4aef84ac30f"
      ],
      "layout": "IPY_MODEL_e70183b7122c440eb0ad820a34ecd0b1"
     }
    },
    "18c1a70d11484b20b0c129afda607eec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19474c3fd67d4a0a9071442553eea424": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a51f8804e64e41f4b5f403bb48f97739",
      "placeholder": "​",
      "style": "IPY_MODEL_7d182abc791a4529a1d022c73f147743",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "19f7599c3e474401aa66b205209c5b05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_88f835bb9ef046ccbf32c41db3d752fc",
       "IPY_MODEL_c22e35a67d6546868f601f486faaa09f",
       "IPY_MODEL_ce52ffbce8164fd3b6f05f8e2f157bf8"
      ],
      "layout": "IPY_MODEL_9f1f657d2e3c47ffabe49528cb850edc"
     }
    },
    "1a501100f02d48bf8e6746ef3cd4047e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c514cd5db254fd887496cfcea29b203": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ce9fb4fb360443fbab1bc426b84e51e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e6693fba36444749c5190ae984b7761": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f8684abca0c45b4a8c36f854fc1e15b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a843939563ee45299fdd3f32986462c5",
      "max": 52002,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8d96f84cdd14438baf1a5c5e4badd284",
      "value": 52002
     }
    },
    "22edcfad17e9407d84b0d169818bd86f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "231d1e98fa704113bb70a4aef84ac30f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e6693fba36444749c5190ae984b7761",
      "placeholder": "​",
      "style": "IPY_MODEL_5e1f0774a45141149ba3a9a62e2d50f1",
      "value": " 52002/52002 [00:03&lt;00:00, 17065.32 examples/s]"
     }
    },
    "2342b7593577476ebc15b5b0b7c93d37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2375ae0eb6c541b086ce027a7368e86a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "25397a2b86ef492c95c76b595f288e0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36412dbe8646468dbc51dbac72ac305c",
      "placeholder": "​",
      "style": "IPY_MODEL_70bb803085a2457092d4642a3baf8f54",
      "value": "Extending conversations: 100%"
     }
    },
    "25c75bff6c7d40148ef6311860013ae8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2748bc11780947038af15b94cdc0565a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91b8e492c8e14eba9e9cd3c857e464ac",
      "max": 52002,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2342b7593577476ebc15b5b0b7c93d37",
      "value": 52002
     }
    },
    "29b8a584ae494edbaa5d1573bd2cc405": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a27e2ac34184a1e88652c377c516d07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_848f2ab429a2449daa889bc5daf315d4",
       "IPY_MODEL_8f2008bd1c9e4979a69151c7056dbd68",
       "IPY_MODEL_6b01f9604205455f8d887d5f216d845d"
      ],
      "layout": "IPY_MODEL_830101e5c8f7425886318bf7bf368128"
     }
    },
    "2bba477ee49f425aac6be9a9e788c28b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b398a7d22a424d7d9ae67afdd95dcdcd",
      "placeholder": "​",
      "style": "IPY_MODEL_bc84a9ff36f143248ea6c2181f68ae02",
      "value": "Converting to ShareGPT: 100%"
     }
    },
    "2d15261428824594908bd697644d61ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62191c10c14c4728bf85a293d29d37ce",
      "placeholder": "​",
      "style": "IPY_MODEL_ec56936c53984c85ade94df6ce443ad5",
      "value": " 52002/52002 [01:18&lt;00:00, 804.54 examples/s]"
     }
    },
    "2ef094bd791b45169fb3de9eea3858f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f8928b10d9a44e6b2c03fee74973d61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32f125cf43cd40a4b232d80a4cd0594f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33a01d898ffc4a1a865b3c899df46981": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "33f7cdb4b1484ff08d5882e38ed4ff33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "36412dbe8646468dbc51dbac72ac305c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39ac8df581254571bf15e52778564ad6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_890767e37b054db5b6b2df4bb2ad351d",
      "placeholder": "​",
      "style": "IPY_MODEL_e9c0e9a6545c49b9895f751b6c738974",
      "value": " 52002/52002 [00:02&lt;00:00, 19246.38 examples/s]"
     }
    },
    "3bd2b3b05e214b8b918cb37bf8b87c4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bfbb892f9fe4c7baec8518c5fc27fd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c186c44416447daaa58e288416b69a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d8e6f188bf44dba981e445d8bea3402": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f30c80db3c54588b79e9352f57e783d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40ec2d13fcc14995b86d2f28a7ae9f37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43efda3bc6a5496aab27c30c99577825": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43f6c10a2c3c478fba1a3784f75c6b84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7474eb738ef64c8aa24c7dadcc296309",
      "placeholder": "​",
      "style": "IPY_MODEL_3c186c44416447daaa58e288416b69a4",
      "value": "Flattening the indices: 100%"
     }
    },
    "44e1233f423e4fb7bc8e94c98449f524": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97f798f38c9c4456ab6c5235d8af9e7d",
      "placeholder": "​",
      "style": "IPY_MODEL_33a01d898ffc4a1a865b3c899df46981",
      "value": "Flattening the indices: 100%"
     }
    },
    "45165ac4e08f4103815205cc37690726": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45d8edc7203e4d2081170777d5eda422": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a7639181756463fa0d2bdcddb0ee460": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2bba477ee49f425aac6be9a9e788c28b",
       "IPY_MODEL_057825aa7df44d8eb9657aa8244c6a56",
       "IPY_MODEL_bc1a5a549e4845b2a549c4a5a077b100"
      ],
      "layout": "IPY_MODEL_22edcfad17e9407d84b0d169818bd86f"
     }
    },
    "4aab9fa7e38a49e59f87515e7bf415ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86f7a51468b248c8bb32c184f7cc4a69",
      "placeholder": "​",
      "style": "IPY_MODEL_43efda3bc6a5496aab27c30c99577825",
      "value": "model.safetensors: 100%"
     }
    },
    "4c4bc99385eb49dd95ad4b740b949e55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4dac566fd3ee404a8308026caf52e165": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4ebfd9be5b684da9a98c007084813595",
       "IPY_MODEL_1f8684abca0c45b4a8c36f854fc1e15b",
       "IPY_MODEL_be28376dcf0a4540872cabee59e87a64"
      ],
      "layout": "IPY_MODEL_50ec7aa2658e4cdf878dbd4c98660072"
     }
    },
    "4e76d402b4e4416e9b7e437af31ad66e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ebfd9be5b684da9a98c007084813595": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f808dffe6c24927b1b87b1319ccb311",
      "placeholder": "​",
      "style": "IPY_MODEL_948f186726e340d18abc9ac134630fcb",
      "value": "Merging columns: 100%"
     }
    },
    "4ef743732002497395f3c2215713eb3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_44e1233f423e4fb7bc8e94c98449f524",
       "IPY_MODEL_69cee937c2bb46528db052e775896eaa",
       "IPY_MODEL_f9c775663b86483abcedd9beba15662b"
      ],
      "layout": "IPY_MODEL_9a301b9b504543008aa9cdb0ec09cdc2"
     }
    },
    "4f78fb604b944c8da3f8f94a84779533": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f808dffe6c24927b1b87b1319ccb311": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5064b0b9c6d7462190bcd6059a6475f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_19474c3fd67d4a0a9071442553eea424",
       "IPY_MODEL_cdc0128cc0ea40bc949df6412d179b78",
       "IPY_MODEL_b28fd98a29b04febac41b3f0169c72a1"
      ],
      "layout": "IPY_MODEL_e0d4b6fedf2245e1b926c36bc7d792e6"
     }
    },
    "50ec7aa2658e4cdf878dbd4c98660072": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "520dd5d7080d46e29213ab6958131a04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "571fbb27971e4af0b958591a502e1249": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d792fa2e810a4aec841b96aed03f22e5",
       "IPY_MODEL_5a927d80c3d841768f8a32abc2b3da4e",
       "IPY_MODEL_60a2e5edb2424b91b551abaf8607d225"
      ],
      "layout": "IPY_MODEL_aa461878d707464ea5728e857199fc1b"
     }
    },
    "5a927d80c3d841768f8a32abc2b3da4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f30c80db3c54588b79e9352f57e783d",
      "max": 350,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6e059c44581046c6b7ac232fac94c6a4",
      "value": 350
     }
    },
    "5ad5ec145642450bb2b3c3b2e0dada54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e1f0774a45141149ba3a9a62e2d50f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e8a3854fa4445b3b3a09a4db9a59de4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5edc00f7efce452e82b713120068d5ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9a05e6b44b2147c99a54764f01910b30",
       "IPY_MODEL_916ab8f1faf14632bdb3dead624eb21f",
       "IPY_MODEL_de5c470b9d654008bb0032b5aa4329ce"
      ],
      "layout": "IPY_MODEL_602377d8635c49118036fbb6817b3cee"
     }
    },
    "602377d8635c49118036fbb6817b3cee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60a2e5edb2424b91b551abaf8607d225": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b2f0019c68b4ca385fc9e9641e98006",
      "placeholder": "​",
      "style": "IPY_MODEL_3bfbb892f9fe4c7baec8518c5fc27fd3",
      "value": " 350/350 [00:00&lt;00:00, 21.6kB/s]"
     }
    },
    "61e2f95ccaf84962a319224b652af287": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62191c10c14c4728bf85a293d29d37ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63b2683594c44b858c937349019c6d0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "665de9c511234f50b95f019e30553647": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7833e5ff39994bd8af56ab74ca5a6282",
       "IPY_MODEL_05e9011d5fd44a219ef86ce93b400cdb",
       "IPY_MODEL_9009e3ae003b4189bbfc8f6d20e425db"
      ],
      "layout": "IPY_MODEL_feddd2b94ff640019168f085886042ca"
     }
    },
    "669649c93c60494fac2bc7dfb4b43ac1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c37f06b87a9b41ba957ac760aad0ea48",
      "placeholder": "​",
      "style": "IPY_MODEL_9c9436e28d9c4cfdb9a251ce1ee4cb39",
      "value": " 52002/52002 [00:05&lt;00:00, 7224.96 examples/s]"
     }
    },
    "66d602f02ee94a9fb9bb3ef6ebb157a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6919b1082780411aa9310ceb152ea6e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99e3b13809ca4873a44189f298084c59",
      "placeholder": "​",
      "style": "IPY_MODEL_701f88ce88074492a3a8b3470e8b22e7",
      "value": "generation_config.json: 100%"
     }
    },
    "69c3b6e19c4d4abbb1e4a42a5be79e62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18c1a70d11484b20b0c129afda607eec",
      "max": 52002,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f90e7b0952a04982acc7b4e4128aa822",
      "value": 52002
     }
    },
    "69cee937c2bb46528db052e775896eaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ff4bb32f392421097f322b035208e6b",
      "max": 52002,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e815c4a6522142068f09ed0abe3d5761",
      "value": 52002
     }
    },
    "6b01f9604205455f8d887d5f216d845d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f8928b10d9a44e6b2c03fee74973d61",
      "placeholder": "​",
      "style": "IPY_MODEL_5e8a3854fa4445b3b3a09a4db9a59de4",
      "value": " 48.4M/48.4M [00:00&lt;00:00, 147MB/s]"
     }
    },
    "6b2f0019c68b4ca385fc9e9641e98006": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c96874fffb648708eba436836dec3c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e059c44581046c6b7ac232fac94c6a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6f6d146e3dc1428682d6f9c193f8bf19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6919b1082780411aa9310ceb152ea6e0",
       "IPY_MODEL_8f9e359dcc0d4e4495eaa1f3920e803b",
       "IPY_MODEL_8a41d23dbbdb44f4aab5f453c4be58a4"
      ],
      "layout": "IPY_MODEL_f06db96ad2414b679cc0b55f25ff16db"
     }
    },
    "6ff4bb32f392421097f322b035208e6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "701f88ce88074492a3a8b3470e8b22e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70bb803085a2457092d4642a3baf8f54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7190e73a16b34eaabf2e3fc00f17246e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7474eb738ef64c8aa24c7dadcc296309": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7833e5ff39994bd8af56ab74ca5a6282": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66d602f02ee94a9fb9bb3ef6ebb157a2",
      "placeholder": "​",
      "style": "IPY_MODEL_bad159b09d454000bba39dba607b8e60",
      "value": "tokenizer.json: 100%"
     }
    },
    "7949c2ae13f44c609de332549305efd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d182abc791a4529a1d022c73f147743": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f107e2a1d274a2f9bec4acce979d2da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8061d66b27d548ea86d7ef10d2d784e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "830101e5c8f7425886318bf7bf368128": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "848f2ab429a2449daa889bc5daf315d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a63b105990504c248cf4eebc42faaba8",
      "placeholder": "​",
      "style": "IPY_MODEL_2375ae0eb6c541b086ce027a7368e86a",
      "value": "(…)-00000-of-00001-6ef3991c06080e14.parquet: 100%"
     }
    },
    "84f9e22160d74ec498f99e9c93b0c8bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ce9fb4fb360443fbab1bc426b84e51e",
      "placeholder": "​",
      "style": "IPY_MODEL_61e2f95ccaf84962a319224b652af287",
      "value": "Map: 100%"
     }
    },
    "86f7a51468b248c8bb32c184f7cc4a69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "886ccb525cb149dfb49be917882f4ae3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_43f6c10a2c3c478fba1a3784f75c6b84",
       "IPY_MODEL_69c3b6e19c4d4abbb1e4a42a5be79e62",
       "IPY_MODEL_d3e8cc7d6db94605ab85f3a41c03a046"
      ],
      "layout": "IPY_MODEL_0bdef7784bb9486091ef72fa30911f17"
     }
    },
    "88f835bb9ef046ccbf32c41db3d752fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ef094bd791b45169fb3de9eea3858f7",
      "placeholder": "​",
      "style": "IPY_MODEL_29b8a584ae494edbaa5d1573bd2cc405",
      "value": "Generating train split: 100%"
     }
    },
    "890767e37b054db5b6b2df4bb2ad351d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a41d23dbbdb44f4aab5f453c4be58a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d8e6f188bf44dba981e445d8bea3402",
      "placeholder": "​",
      "style": "IPY_MODEL_a615710d2f72406f94586cf44320d1d8",
      "value": " 198/198 [00:00&lt;00:00, 14.4kB/s]"
     }
    },
    "8c321f9d450c45259553f244cea495ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d96f84cdd14438baf1a5c5e4badd284": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8f2008bd1c9e4979a69151c7056dbd68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09d4965cff9a457e91bc2ed788b37d98",
      "max": 48393562,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b5e79d185ecf496890db8818b0b60306",
      "value": 48393562
     }
    },
    "8f9e359dcc0d4e4495eaa1f3920e803b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b91f7a6e50b5463bb560e45a71ee1998",
      "max": 198,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f7ef65c1668c498bb72ba3411301e116",
      "value": 198
     }
    },
    "9009e3ae003b4189bbfc8f6d20e425db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c514cd5db254fd887496cfcea29b203",
      "placeholder": "​",
      "style": "IPY_MODEL_4f78fb604b944c8da3f8f94a84779533",
      "value": " 9.09M/9.09M [00:00&lt;00:00, 33.7MB/s]"
     }
    },
    "90323c950496418d8540e5e9dfc7db31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "916ab8f1faf14632bdb3dead624eb21f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bd2b3b05e214b8b918cb37bf8b87c4b",
      "max": 52002,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b23419db6d7b41af9769c4c7535d5145",
      "value": 52002
     }
    },
    "91b8e492c8e14eba9e9cd3c857e464ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9249cef6e8824525a1e183498d9d41ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "948f186726e340d18abc9ac134630fcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96aad118d29c4178b429612b2276ddfd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97f798f38c9c4456ab6c5235d8af9e7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99e3b13809ca4873a44189f298084c59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a05e6b44b2147c99a54764f01910b30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e660f7079e4346e499da1ac196c96980",
      "placeholder": "​",
      "style": "IPY_MODEL_fa70fc9faa8a4580bf44e07f65e4d092",
      "value": "Flattening the indices: 100%"
     }
    },
    "9a301b9b504543008aa9cdb0ec09cdc2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b918d8d5f674be88e05c0f3fc365b77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9bc07321be954d109b8f27d4b8f181dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9c9436e28d9c4cfdb9a251ce1ee4cb39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f1f657d2e3c47ffabe49528cb850edc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a10a1f9bf41540ddb33c2b8dc181947e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a1d70bbc33a64c23a63f773abc5e22e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_84f9e22160d74ec498f99e9c93b0c8bc",
       "IPY_MODEL_cb89bc91831b431bba8b1f1a14ac05ec",
       "IPY_MODEL_669649c93c60494fac2bc7dfb4b43ac1"
      ],
      "layout": "IPY_MODEL_c821f5cc39924fde9fc9d381747bc5d3"
     }
    },
    "a4df6bc79d93441283021cad1e4535e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b522d2d378de44329f3224533318eb25",
      "max": 3385,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a10a1f9bf41540ddb33c2b8dc181947e",
      "value": 3385
     }
    },
    "a51f8804e64e41f4b5f403bb48f97739": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a615710d2f72406f94586cf44320d1d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a63b105990504c248cf4eebc42faaba8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a79fd1eef2c543f9bef6ff4c78b7b9ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14c60f02caa441b7a5ce09ffd770f5a9",
      "max": 52002,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ea6a29aacd804453863970f0e4bfb4ba",
      "value": 52002
     }
    },
    "a843939563ee45299fdd3f32986462c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9a39684291d4eb1b7312640feae1462": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f107e2a1d274a2f9bec4acce979d2da",
      "placeholder": "​",
      "style": "IPY_MODEL_0d5da7e017424aa0b7ff0d40abad1ecc",
      "value": "Map (num_proc=2): 100%"
     }
    },
    "aa461878d707464ea5728e857199fc1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af205ba151054c5fa8a5761b24dc8445": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9031d9400464ce4a500bd5b0b1b1fc7",
      "placeholder": "​",
      "style": "IPY_MODEL_33f7cdb4b1484ff08d5882e38ed4ff33",
      "value": " 5.70G/5.70G [00:43&lt;00:00, 300MB/s]"
     }
    },
    "b03af9d3d3074c9fb43cc45d456b8e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4aab9fa7e38a49e59f87515e7bf415ee",
       "IPY_MODEL_cba1bb5319c04c4c8adbc2304af6dde7",
       "IPY_MODEL_af205ba151054c5fa8a5761b24dc8445"
      ],
      "layout": "IPY_MODEL_45d8edc7203e4d2081170777d5eda422"
     }
    },
    "b13a48803a164e7caecfb06e2bde1556": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1e8d77d5bc34e99824c873e55cc49a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b23419db6d7b41af9769c4c7535d5145": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b28fd98a29b04febac41b3f0169c72a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c96874fffb648708eba436836dec3c7",
      "placeholder": "​",
      "style": "IPY_MODEL_8c321f9d450c45259553f244cea495ce",
      "value": " 50.6k/50.6k [00:00&lt;00:00, 2.69MB/s]"
     }
    },
    "b398a7d22a424d7d9ae67afdd95dcdcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3a8a71922f341758e1adf0f951208bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b522d2d378de44329f3224533318eb25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5e79d185ecf496890db8818b0b60306": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b77913d6312d4608bdfa405fcaf16022": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b91f7a6e50b5463bb560e45a71ee1998": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bad159b09d454000bba39dba607b8e60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bc1a5a549e4845b2a549c4a5a077b100": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ad5ec145642450bb2b3c3b2e0dada54",
      "placeholder": "​",
      "style": "IPY_MODEL_c5d04e56aaef4276b8da7b1d47eda54c",
      "value": " 52002/52002 [00:01&lt;00:00, 40478.66 examples/s]"
     }
    },
    "bc84a9ff36f143248ea6c2181f68ae02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be28376dcf0a4540872cabee59e87a64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e829599ab414438f9b65c3dbe151ab2f",
      "placeholder": "​",
      "style": "IPY_MODEL_520dd5d7080d46e29213ab6958131a04",
      "value": " 52002/52002 [00:01&lt;00:00, 60921.19 examples/s]"
     }
    },
    "c22e35a67d6546868f601f486faaa09f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63b2683594c44b858c937349019c6d0d",
      "max": 52002,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cead1d73fc484c12ab7b7e4dcbfed58b",
      "value": 52002
     }
    },
    "c2ec9b62f02b4813ab4d7a7c4609ec57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c37f06b87a9b41ba957ac760aad0ea48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4df80b7320a4022aa91a8b3f0c49827": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d760752518e841a2a03f68914e21602f",
      "placeholder": "​",
      "style": "IPY_MODEL_90323c950496418d8540e5e9dfc7db31",
      "value": " 3.38k/3.38k [00:00&lt;00:00, 54.4kB/s]"
     }
    },
    "c5d04e56aaef4276b8da7b1d47eda54c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c821f5cc39924fde9fc9d381747bc5d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb89bc91831b431bba8b1f1a14ac05ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbf4c274668c4feeb407501754eb7bf1",
      "max": 52002,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9249cef6e8824525a1e183498d9d41ac",
      "value": 52002
     }
    },
    "cba1bb5319c04c4c8adbc2304af6dde7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d2d931811914399b33af27d741cdbd2",
      "max": 5702746405,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7190e73a16b34eaabf2e3fc00f17246e",
      "value": 5702745862
     }
    },
    "cbf4c274668c4feeb407501754eb7bf1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdc0128cc0ea40bc949df6412d179b78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b13a48803a164e7caecfb06e2bde1556",
      "max": 50641,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9bc07321be954d109b8f27d4b8f181dd",
      "value": 50641
     }
    },
    "ce52ffbce8164fd3b6f05f8e2f157bf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40ec2d13fcc14995b86d2f28a7ae9f37",
      "placeholder": "​",
      "style": "IPY_MODEL_25c75bff6c7d40148ef6311860013ae8",
      "value": " 52002/52002 [00:01&lt;00:00, 51272.54 examples/s]"
     }
    },
    "cead1d73fc484c12ab7b7e4dcbfed58b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cedf19b766684a1f8b2e40d1f97e89a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d08ffe495f9649cd99fd13e38fa09aa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0a12ecf2f7b4af59ad6b9c6806cffd2",
       "IPY_MODEL_2748bc11780947038af15b94cdc0565a",
       "IPY_MODEL_39ac8df581254571bf15e52778564ad6"
      ],
      "layout": "IPY_MODEL_32f125cf43cd40a4b232d80a4cd0594f"
     }
    },
    "d3e8cc7d6db94605ab85f3a41c03a046": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e76d402b4e4416e9b7e437af31ad66e",
      "placeholder": "​",
      "style": "IPY_MODEL_12e4386de36246c28a70205ad43dc5d3",
      "value": " 52002/52002 [00:00&lt;00:00, 160344.47 examples/s]"
     }
    },
    "d7435502d95f4355b37d2f3332b057f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c4bc99385eb49dd95ad4b740b949e55",
      "max": 52002,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f62d1a6521574459ae6fb1ebd71ad631",
      "value": 52002
     }
    },
    "d760752518e841a2a03f68914e21602f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d792fa2e810a4aec841b96aed03f22e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2ec9b62f02b4813ab4d7a7c4609ec57",
      "placeholder": "​",
      "style": "IPY_MODEL_7949c2ae13f44c609de332549305efd4",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "db6e9ea5d4ac4ceeb6216973ab04fff2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd0bd629b2384bd4aa4da791c3d6d254": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de5c470b9d654008bb0032b5aa4329ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96aad118d29c4178b429612b2276ddfd",
      "placeholder": "​",
      "style": "IPY_MODEL_8061d66b27d548ea86d7ef10d2d784e8",
      "value": " 52002/52002 [00:11&lt;00:00, 4398.24 examples/s]"
     }
    },
    "dee51ee264e24b809be18f6d286ae874": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a9a39684291d4eb1b7312640feae1462",
       "IPY_MODEL_d7435502d95f4355b37d2f3332b057f1",
       "IPY_MODEL_2d15261428824594908bd697644d61ed"
      ],
      "layout": "IPY_MODEL_b3a8a71922f341758e1adf0f951208bb"
     }
    },
    "e0a12ecf2f7b4af59ad6b9c6806cffd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a3dd767c8284aa899195fb798a5da74",
      "placeholder": "​",
      "style": "IPY_MODEL_05e65597d7804e8eaa92d0df28a03b95",
      "value": "Standardizing format: 100%"
     }
    },
    "e0d4b6fedf2245e1b926c36bc7d792e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e16a04efe0564f13bda5d36487b79053": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e660f7079e4346e499da1ac196c96980": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e70183b7122c440eb0ad820a34ecd0b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7c4177a28d34f6da992178c8cb9313c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ffe387f8ca604781a7cd92a44c6dd508",
       "IPY_MODEL_a4df6bc79d93441283021cad1e4535e3",
       "IPY_MODEL_c4df80b7320a4022aa91a8b3f0c49827"
      ],
      "layout": "IPY_MODEL_dd0bd629b2384bd4aa4da791c3d6d254"
     }
    },
    "e815c4a6522142068f09ed0abe3d5761": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e829599ab414438f9b65c3dbe151ab2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9c0e9a6545c49b9895f751b6c738974": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea6a29aacd804453863970f0e4bfb4ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ec56936c53984c85ade94df6ce443ad5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f06db96ad2414b679cc0b55f25ff16db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f62d1a6521574459ae6fb1ebd71ad631": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f7ef65c1668c498bb72ba3411301e116": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f9031d9400464ce4a500bd5b0b1b1fc7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f90e7b0952a04982acc7b4e4128aa822": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f9c775663b86483abcedd9beba15662b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45165ac4e08f4103815205cc37690726",
      "placeholder": "​",
      "style": "IPY_MODEL_b1e8d77d5bc34e99824c873e55cc49a2",
      "value": " 52002/52002 [00:17&lt;00:00, 2977.05 examples/s]"
     }
    },
    "fa70fc9faa8a4580bf44e07f65e4d092": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "feddd2b94ff640019168f085886042ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffe387f8ca604781a7cd92a44c6dd508": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db6e9ea5d4ac4ceeb6216973ab04fff2",
      "placeholder": "​",
      "style": "IPY_MODEL_cedf19b766684a1f8b2e40d1f97e89a4",
      "value": "README.md: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
